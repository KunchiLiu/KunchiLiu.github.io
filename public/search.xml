<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CCF2020风电机组异常数据识别与清洗方案分享</title>
      <link href="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/"/>
      <url>/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<p>2020年10月，在CCF大赛主页看到了<a href="https://www.datafountain.cn/competitions/451" target="_blank" rel="noopener">风电机组异常数据识别与清洗</a>的比赛，提供了12台风机的一年的SCADA（数据采集与监视控制系统）真实运行数据，因为收集的数据来自实际运行的风机，存在大量异常点，举办方希望参赛者根据提供的数据集建立无监督聚类模型，识别出SCADA数据中的异常数据。我们比赛中最好成绩排名为第6名，后来有好多大神找到了更多的异常点，排名直线上升。我们A榜最终成绩排名为15/1122，B榜最终成绩排名为18/1122。</p><p>CCF大赛官网：<a href="https://www.datafountain.cn/competitions" target="_blank" rel="noopener">https://www.datafountain.cn/competitions</a></p><p>比赛链接：<a href="https://www.datafountain.cn/competitions/451" target="_blank" rel="noopener">https://www.datafountain.cn/competitions/451</a></p><a id="more"></a><h2 id="赛题任务"><a href="#赛题任务" class="headerlink" title="赛题任务"></a>赛题任务</h2><p>依据提供的12台风力电机1年的10min间隔SCADA运行数据，<strong>包括时间戳信息、风速信息、风机转速信息和功率信息等</strong>，利用机器学习相关技术，建立鲁棒的风电机组异常数据检测模型，用于识别并剔除潜在的异常数据，提高数据质量。此任务未给出异常数据标签，可看做聚类任务，为引导选手向赛题需求对接，现简单阐述异常数据定义。异常数据是由风机运行过程与设计运行工况出现较大偏离时产生，如风速仪测风异常导致采集的功率散点明显偏离设计风功率。</p><h2 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h2><ul><li>数据文件依次为：</li></ul><div class="table-container"><table><thead><tr><th>文件类别</th><th>文件名</th><th>文件内容</th></tr></thead><tbody><tr><td>数据集</td><td>dataset.csv</td><td>12台风机运行数据文件，无标签</td></tr><tr><td>提交样例</td><td>submission.csv</td><td>仅有三个字段WindNumber\Time\label</td></tr></tbody></table></div><ul><li>数据集中各个字段说明如下：</li></ul><div class="table-container"><table><thead><tr><th>字段英文名</th><th>字段中文名</th></tr></thead><tbody><tr><td>Time</td><td>时间戳</td></tr><tr><td>WindSpeed</td><td>风速</td></tr><tr><td>Power</td><td>功率</td></tr><tr><td>RotorSpeed</td><td>风轮转速</td></tr><tr><td>WindNumber</td><td>风机编号</td></tr></tbody></table></div><ul><li>风机参数说明如下：</li></ul><div class="table-container"><table><thead><tr><th>风机编号</th><th>风轮直径</th><th>额定功率</th><th>切入风速</th><th>切出风速</th><th>风轮转速范围</th></tr></thead><tbody><tr><td></td><td>(m)</td><td>(kW)</td><td>(m/s)</td><td>(m/s)</td><td>(r/min)</td></tr><tr><td>1#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>2#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>3#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>4#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>5#</td><td>100.5</td><td>2000</td><td>3</td><td>22</td><td>5.5-19</td></tr><tr><td>6#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>7#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>8#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>9#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>10#</td><td>99</td><td>2000</td><td>3</td><td>25</td><td>8.33-16.8</td></tr><tr><td>11#</td><td>115</td><td>2000</td><td>2.5</td><td>19</td><td>5-14</td></tr><tr><td>12#</td><td>104.8</td><td>2000</td><td>3</td><td>22</td><td>5.5-17</td></tr></tbody></table></div><ul><li>另外，评测标准是12台风机的平均F1值。</li></ul><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>首先，解决这个赛题的方法是无监督学习方法。不是简单的二分类问题，因为没有标签。如果通过半监督的方式进行人为打标，会由于数据量大、费事费力、标注不一定准确，而导致风险过大，造成过拟合。然后，我们发现12台风机的特征中【时间戳，风速，风轮转速，功率】，时间戳是以10分钟为间隔进行采集的，这是一致的。因此，在后续主要分析了风速与功率、风轮转速与功率的关系，即三个特征【风速，风轮转速，功率】。接下来，我们分别计算了12台风机中三个特征的协方差系数，发现风速和风轮转速的相似程度很高，因此，在后续的聚类方法中，更多的是只考虑风速和功率之间的散点图关系，来评估每种方法检测出的异常点是否合理。</p><h3 id="单个特征的可视化"><a href="#单个特征的可视化" class="headerlink" title="单个特征的可视化"></a>单个特征的可视化</h3><ul><li>12台风机的功率密度直方图：可以看出每台风机功率的分布并不是呈现正态分布，12台风机功率在0值附近概率分布较大。</li></ul><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/Power.png" alt="power"></p><ul><li>12台风轮转速密度直方图：从图中可以看出除了10号风机，其他的风轮转速为0的概率密度较高，12号风轮更为异常。因此，可以分析分析出风轮转速应主要集中于8-15之间，在此范围外的风机转速出现异常数据可能性较大。</li></ul><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/RotorSpeed.png" alt="image-20210227121726076"></p><ul><li>风速密度直方图：可以看出大部分风机的样本风速呈现正态分布，其中6号风机和12号风机呈现正偏态。</li></ul><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/WindSpeed.png" alt="image-20210227121736954"></p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>我们的方法主要</p><h3 id="基于规则的方法"><a href="#基于规则的方法" class="headerlink" title="基于规则的方法"></a>基于规则的方法</h3><p>这里主要根据数据说明中的风机参数来进行判定，起初我们严格按照每天风机对应的参数来检测出每台风机的异常点（第一步检测），后来，看群里讨论，说给定的风轮转速偏高，于是我们进行逐步检测，比如同一类型的一致，不同类型的分别测，最终找的较为理想的是风轮转速全部定为5r/min为最好（这里我们不一定测得是最优值）。故基于规则的方法将判断出3类异常点：</p><ul><li>小于0的风速、小于0的风机功率以及风轮转速小于5的记录标记为异常点。</li><li>低于对应风机的切入风速，且风机功率大于0的记录标记为异常点。</li><li>所有风速大于12.5m/s且功率在1500kW以下的记录标记为异常点。</li></ul><p>此时，可以看一下风速-功率曲线图（红色点为当前步骤筛选出的异常点）：</p><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/WindSpeed_Power_0-Gt-Zero-Condition_all.png" alt="WindSpeed_Power_0-Gt-Zero-Condition_all">上述可以发现部分风机都有多条风速-功率曲线，但只有一条是正常值，比如3号和4号风机，矮的肯定是异常点，接下来讲述如何去掉唉矮的这条曲线。</p><ul><li><p>准备工作，这里要用到风轮转速立方-功率曲线，利用下文提到的四分位法，不过不是按25%和75%划分，而是0%到90%来还划分，风轮转速立方的间隔取100，每个风机的风轮转速立方范围不一致，所以有哦不同的总间隔数。这里去掉这些散点，是为了便于下一步的保留一条曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># except_one_step()每个风机分开执行</span></span><br><span class="line">result = except_one_step(dataset=dataset_pr,model=QuartileModel(by=(<span class="string">'RotorSpeedCube'</span>, <span class="number">100</span>), low_percent=<span class="number">0</span>, high_percent=<span class="number">90</span>), del_col=<span class="string">'WindSpeed'</span>)</span><br></pre></td></tr></table></figure></li><li><p>去除其他风轮转速立方-功率异常曲线，只保留一条。具体操作是异常曲线的点密度低于正常曲线（比较细长），对于风机功率，我们取100为间隔，对于风轮转速立方，我们取50为间隔，统计个每个区间内点的个数。小于10的异常的区间，大于50的我们将其作为正常值，也可看做有效最高峰。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = except_one_step(dataset=dataset_pr,model=SplitHistogram(bin_col=<span class="string">'Power'</span>, bin_range=<span class="number">50</span>, by=(<span class="string">'RotorSpeedCube'</span>, <span class="number">50</span>)), del_col=<span class="string">'WindSpeed'</span>)</span><br></pre></td></tr></table></figure></li><li><p>但是上述两步会存在误标点，即把正常的点标记为异常的点，比如风机5和风机11有很多误标点。因此这两步检测出的异常点为记录下来，后续会利用恢复模型来将其纠正为正常点。利用风轮转速处理后，得到的风速-风机功率曲线图如下：</p></li></ul><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/WindSpeed_Power_2-PR-SplitHistogram-RotorSpeedCube_all.png" alt="WindSpeed_Power_0-Gt-Zero-Condition_all"></p><h3 id="四分位法（Quartile-Method）"><a href="#四分位法（Quartile-Method）" class="headerlink" title="四分位法（Quartile Method）"></a>四分位法（Quartile Method）</h3><p>四分位数法是找到将有序数据集划分为四个相等部分的三个数值，每个部分包含数据集中总观测值的25%。举个例子来说，一个风机数据集包含<script type="math/tex">n</script>个功率观测值<script type="math/tex">\boldsymbol{P}_v={p_1,p_2,...,p_n}</script>，那么如何利用四分位法检测异常值呢？</p><ol><li><p>计算第二个分位数<script type="math/tex">P_2</script>，即找到中位数：</p><script type="math/tex; mode=display">\begin{aligned}P_2\begin{cases}p_{\frac{n+1}{2}} &n=2k+1;k=0,1,2,... \\0.5p_{\frac{n}{2}}+0.5p_{\frac{n+2}{2}} &n=2k,k=1,2,...\end{cases}\end{aligned}</script></li><li><p>计算第一个和第三个分位数：</p><ul><li><p>如果<script type="math/tex">n=2k(k=1,2,3,...)</script>，可利用第一步的<script type="math/tex">P_2</script>将<script type="math/tex">\boldsymbol{P}_v</script>分为两部分，利用1种的公式找到俩部分的二分位数记为<script type="math/tex">P_1</script>和<script type="math/tex">P_3</script>。</p></li><li><p>如果<script type="math/tex">n=4k+3(k=0，1,2,...)</script>，则：</p><script type="math/tex; mode=display">\begin{aligned}P1 &=0.75p_{k+1} + 0.25p_{k+2}\\P3 &=0.25p_{3k+2} + 0.75p_{3k+3}\end{aligned}</script></li><li><p>如果<script type="math/tex">n=4k+1(k=0,1,2,...)</script>，则：</p><script type="math/tex; mode=display">\begin{aligned}P1 &=0.25p_{k} + 0.75p_{k+1}\\P3 &=0.75p_{3k+1} + 0.25p_{3k+2}\end{aligned}</script></li></ul></li><li><p>正常数据和异常数据判断。得到了<script type="math/tex">P_1</script>和<script type="math/tex">P_3</script>，我们可以计算出四分位间距（Interquartile Range，IQR）：</p><script type="math/tex; mode=display">\begin{aligned}IQR = P_3 - P_1\end{aligned}</script><p>则<script type="math/tex">\boldsymbol{P}_v</script>的正常数据范围为：</p><script type="math/tex; mode=display">\begin{aligned}{[F_l,F_u]} &=[P_1 - 1.5IQR,P_3+1.5IQR]\\\end{aligned}</script><p>其中<script type="math/tex">F_l</script>为下界，<script type="math/tex">F_u</script>为上界。</p></li></ol><p>一般来说，真实场景下风机采集的数据风速-风机功率的曲线图如下所示，可以看出以不同轴划分区间，<script type="math/tex">F_l</script>和<script type="math/tex">F_u</script>之间包含的点基本上都是正常点。下图可以看到只有一条明显的风速-功率曲线，所以我们才要在第一步利用规则的方法去掉风机参数外的异常点和低功率曲线异常点：</p><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/vp_scatters.png" alt="vp_scatters"></p><p>利用四分位法，我们去除了稀疏离群点，包括水平稀疏离群值和垂直稀疏离群点。其中，我们取风机功率的间隔为25，去除了水平稀疏离群点；取风速的间隔为0.5，去除了垂直稀疏离群点，这里离群点即异常点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = except_one_step(dataset=dataset,model=QuartileModel(by=(<span class="string">'Power'</span>, <span class="number">25</span>), low_percent=<span class="number">25</span>, high_percent=<span class="number">75</span>),del_col=<span class="string">'RotorSpeed'</span>)</span><br><span class="line">result = except_one_step(dataset=dataset,model=QuartileModel(by=(<span class="string">'WindSpeed'</span>, <span class="number">0.5</span>), low_percent=<span class="number">25</span>, high_percent=<span class="number">85</span>),del_col=<span class="string">'RotorSpeed'</span>)</span><br></pre></td></tr></table></figure><p>结果如下图：</p><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/WindSpeed_Power_4-PV-Quartile-WindSpeed_all.png" alt="WindSpeed_Power_4-PV-Quartile-WindSpeed_all">下面介绍的是如何利用基于密度聚类的方法检测异常点。</p><h3 id="基于密度聚类的方法"><a href="#基于密度聚类的方法" class="headerlink" title="基于密度聚类的方法"></a>基于密度聚类的方法</h3><p>聚类是无监督学习的重要方法，常见的有哦K-means聚类和分层聚类等，它们把一些对象划分为不同的簇，使得同一个簇内的对象都具有相似的特征，不同簇内的对象则表现出很大的差异。对于不同的风机，由异常点组成的异常簇数量未知且不相同。因此，像K-means这类方法并不适用，因此这里采用了DBSCAN（Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法），它的核心思想是：对于一个簇中的每一个点，该点给定半径范围内至少包含最小数量的点，这个数量记为MinPts。这里先标准化</p><p>同样，对于包含<script type="math/tex">n</script>个功率观测值<script type="math/tex">\boldsymbol{P}_v={p_1,p_2,...,p_n}</script>，DBSCAN的部分定义如下：</p><ol><li>记<script type="math/tex">\boldsymbol{N}_{\varepsilon}(p_i)=\{ p_j \in \boldsymbol{P}_v | dist(p_i, p_j) \le \varepsilon\}</script>为<strong>点<script type="math/tex">p_i</script>的邻域</strong>，其中距离函数<script type="math/tex">dist(p_i, p_j)</script>选用欧式距离；</li><li>如果<script type="math/tex">p_j \in \boldsymbol{N}_{\varepsilon}(p_i)</script>，且<script type="math/tex">p_i</script>的<script type="math/tex">\varepsilon-</script>邻域对应的<script type="math/tex">\boldsymbol{N}_{\varepsilon}(p_i)</script>至少包含MinPts的点，则称点<script type="math/tex">p_j</script>是点<script type="math/tex">p_i</script><strong>密度直达</strong>的点，<script type="math/tex">p_i</script>是一个核心点；（不具有对称性）</li><li>同样，若从点<script type="math/tex">p_i</script>到点<script type="math/tex">p_{i+1}</script>是密度可达的，<script type="math/tex">p_i</script>到<script type="math/tex">p_j</script>中间有一连串密度可达的点，即<script type="math/tex">p_i,p_{i+1},...,p_j</script>，那么<script type="math/tex">p_i</script>到<script type="math/tex">p_j</script>也是<strong>密度可达</strong>的。（不具有对称性）</li><li>对于<script type="math/tex">x_i</script>和<script type="math/tex">x_j</script>，如果存在核心点<script type="math/tex">x_k</script>，使<script type="math/tex">x_i, x_j</script>均由<script type="math/tex">x_k</script>密度可达，则称<script type="math/tex">x_i</script>和<script type="math/tex">x_j</script><strong>密度相连</strong>。（具有对称性）</li><li>对于<script type="math/tex">\varepsilon-</script>邻域和MinPts，一个簇<script type="math/tex">\boldsymbol{C}</script>是满足如下条件的<script type="math/tex">\boldsymbol{P}_v</script>的非空子集：<ul><li>对于<script type="math/tex">\forall p_i,p_j</script>，<script type="math/tex">p_i \in \boldsymbol{C}</script>且<script type="math/tex">p_j</script>由<script type="math/tex">p_i</script>密度可达，那么<script type="math/tex">p_j \in \boldsymbol{C}</script>；</li><li>对于<script type="math/tex">\forall p_i,p_j \in \boldsymbol{C}</script>，<script type="math/tex">p_j</script>和<script type="math/tex">p_i</script>密度相连。</li></ul></li><li>异常点（噪声）是不属于任何簇的点。</li></ol><p>DBSCAN的处理步骤如下：</p><ol><li>设定<script type="math/tex">\varepsilon=0.15</script>，MinPts都设定为7，选的是调参得到的最优值，这里要提前将风速和功率最大最小归一化。</li><li>任意选择一个点<script type="math/tex">p_i</script>，将它标记为已访问，计算出在<script type="math/tex">\varepsilon</script>和MinPts设定下满足密度连接的点，如果<script type="math/tex">p_i</script>是一个核心点，找它的<script type="math/tex">\varepsilon-</script>邻域<script type="math/tex">\boldsymbol{N}</script>，生成一个新的仅包含<script type="math/tex">p_i</script>的簇<script type="math/tex">\boldsymbol{C}</script>；否则标记为异常点。</li><li>遍历<script type="math/tex">\varepsilon-</script>邻域<script type="math/tex">\boldsymbol{N}</script>的每一个点<script type="math/tex">p_j</script>，如果它不属于任何簇，把它加入到簇<script type="math/tex">\boldsymbol{C}</script>；如果它是一个核心点，把<script type="math/tex">p_j</script>的<script type="math/tex">\varepsilon-</script>邻域合并到<script type="math/tex">\boldsymbol{N}</script></li><li>重复步骤3，直到不能找到核心点，然后返回步骤2。</li></ol><p>结果如下：</p><p><img src="/2021/02/25/CCF2020%E9%A3%8E%E7%94%B5%E6%9C%BA%E7%BB%84%E5%BC%82%E5%B8%B8%E6%95%B0%E6%8D%AE%E8%AF%86%E5%88%AB%E4%B8%8E%E6%B8%85%E6%B4%97%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/WindSpeed_Power_5-DBSCAN-WindSpeed_all.png" alt="WindSpeed_Power_5-DBSCAN-WindSpeed_all"></p><p>误标点恢复主要是判断正产点的左右边界，将边界内的误标点都恢复成正常点即可。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://ieeexplore.ieee.org/document/7953532" target="_blank" rel="noopener">Data-Driven Correction Approach to Reﬁne Power Curve of Wind Farm Under Wind Curtailment</a></li><li><a href="https://ccpt.cnki.net/kcms/detail/detail.aspx?filename=DLXT201421007&amp;dbcode=&amp;dbname=CJFD2014&amp;pcode=CRJT&amp;v=MjAwNjhuRDBMVGcyWDJoc3hGckNVUjdxZVplWm1GaW5sVUxyTElTSFRlckc0SDlYT3JvOUZZNFIrQzM4NHpoNFg=&amp;uid=WEEvREcwSlJHSldSdmVqMDh6a1dqRHN5WVAyOERQUldMaExObWJPc1hoST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank" rel="noopener">风电场弃风异常数据簇的特征及处理方法</a></li><li><a href="https://blog.csdn.net/weixin_44132035/article/details/108973264" target="_blank" rel="noopener">数据挖掘—风电机组异常数据识别与清洗</a></li><li><a href="https://www.cnblogs.com/pinard/p/6208966.html" target="_blank" rel="noopener">DBSCAN密度聚类算法</a></li><li><a href="https://www.cnblogs.com/pinard/p/6217852.html" target="_blank" rel="noopener">用scikit-learn学习DBSCAN聚类 </a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 无监督学习 </tag>
            
            <tag> 无监督聚类 </tag>
            
            <tag> DBSCAN </tag>
            
            <tag> 异常数据检测 </tag>
            
            <tag> 四分位法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四篇论文-关于强化学习在自然灾害和智慧城市中的应用</title>
      <link href="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
      <url>/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>这次调研主要是对强化学习在自然灾害和智慧城市中的应用，共包含四篇论文：</p><ul><li>Firm-level behavior control after large-scale urban flooding using multi-agent deep reinforcement learning（GeoSim’19, Chicago, IL, USA）洪灾后企业交易链恢复问题。</li><li>Coordinating Disaster Emergency Response with Heuristic Reinforcement Learning 飓风引发洪灾的救援调度问题。</li><li>Multi-agent reinforcement learning for adaptive demand response in smart cities （Journal of Physics CISBAT 2019）建筑物群控温节省电费问题。</li><li>A Deep Reinforcement Learning-Enabled Dynamic Redeployment System for Mobile Ambulances（2019 UbiComp）救护车护送患者后重新部署问题。</li></ul><p>下面按照应用场景，数据，方法和评估来介绍上述文章。</p><a id="more"></a><h2 id="论文一：企业交易链恢复"><a href="#论文一：企业交易链恢复" class="headerlink" title="论文一：企业交易链恢复"></a>论文一：企业交易链恢复</h2><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/1 ab0.png" alt="洪水模拟"></p><p>这篇文章利用多智能体深度强化学习技术，在洪灾后指导公司采取行为，加快恢复到灾前状态。文章得出的结论是灾后公司应首先采取稳定供应商和开展恢复工作，然后寻找客户和拓展业务。</p><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>文章选取东京荒川盆地，由于该盆地靠近东京城市的中心部分，许多公司都坐落于此。另外，荒川河流流经该盆地，若这条河泛滥，很可能造成巨大的破坏，预计许多企业将被迫长时间停工，并且被淹没的地区要花费一段时间才能完成排水。因此，随着时间的推迟，洪水泛滥造成的损失可能会越来越多。</p><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><ol><li>洪水模拟分析的数据：数据来自国土交通省旅游局（MLIT）荒川下游河道所提供的荒川河流地区洪水模拟结果，洪水模拟场景需要用该数据与MLIT创建的假定洪水淹没区域图绘制手册一起进行。这个数据集包含335个场景，每个场景具有不同的防洪堤破坏位置（个人理解：选取不同的场景，具有不同的防洪堤破坏位置，意味产生随机的初始状态）。这些数据是100 m-mesh图像，包含了如破坏位置和淹没深度的时间序列数据（防洪堤破坏后一个月的时间序列数据，间隔为10分钟）（These data represent 100 m-mesh figures containing information such as breakdown location and time-series (10 minutes time series data for one month after the levee breakdown) data of inundation depth.）。文中采用了由Ikeuchi等人提出的高破坏情景（a scenario with high damage identified）。下图显示了最大淹没深度以及灾难发生后3小时和12小时的淹没深度。洪水从断裂点开始逐渐扩散，在东京市中心的广阔区域内深度最大超过5 m。<img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/1 Pedicted flood situation in Tokyo.png" alt="洪水模拟"></li><li>供应链网络数据：数据集来自信用报告机构Teikoku Databank Ltd.（TDB），该数据集涵盖了2015年近165万家公司总部和580,000家分支机构的信息，在日本所有47个县和地区中，占日本187万家企业的近90％，其中包括162万家注册公司和24万家其他公司（2016年经济普查）。包括<strong>公司的代码，地址，行业类型和销售额</strong>。此外，根据TDB交易数据，2016年有近500万笔企业间交易观测数据。这些数据包括总部之间的交易信息，例如供应商和客户的公司代码，交易项目和估计的交易金额。该公司的代码使网络分析可以与该公司及其分支机构的数据相关联。将该数据的交易量与基于I/O表的区域间交易进行比较，可以得出$R = 0.9$的高相关性，这表明这些数据的交易量足以全面掌握生产活动。</li></ol><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="仿真环境设计"><a href="#仿真环境设计" class="headerlink" title="仿真环境设计"></a>仿真环境设计</h4><p>首先，将位于灾区荒川盆地的大约30,000家公司和170,000个商业伙伴作为agents。Agents之间可以作为业务合作伙伴相互联系。假设一步是一天，则模拟时间是灾难发生后2个月（60步）。模拟的目标是直到整个供应链的交易额恢复到灾难发生前水平的80％。 洪水泛滥地区的每个公司都会根据淹没深度遭受不同程度的洪水破坏，并失去客户和生产能力。模型通过使用深度强化学习通过反复试验，在灾难发生后的这三个时期内（前、中、后期）自主确定对公司行为的最佳控制。</p><p>Agents可以采取5种actions：</p><ol><li>采取恢复行动，可以缩短恢复时间；</li><li>与以前的业务合作伙伴重新签约；</li><li>探索新的业务合作伙伴，可以选择供应商或者客户;</li><li>业务扩展。如果公司有签约客户，则可以增加其中的交易额；</li><li>不采取行动。</li></ol><p>另外，假设agent的行为会影响其他agents，当他们成为业务合作伙伴时，他们在订单接收和下达之间就具有关系，这会影响生产活动。</p><p>假设一个公司的生产力$Y$在恢复过程中，遵循Cobb-Douglas函数：</p><script type="math/tex; mode=display">\begin{aligned}Y = AL^\alpha K^\beta,\alpha=1-\beta,0<\alpha,\beta<1\end{aligned}</script><p>论文中假定比例因子$A$是固定的，$L$为劳动力，$\alpha$为劳动份额 ，$K$为资本，$\beta$为资本份额。假定正常产值为$y$，通过下式来计算洪灾影响的受灾公司的减少产量$\Delta y$：</p><script type="math/tex; mode=display">\begin{aligned}\Delta y=\left\{ \alpha \cdot \frac{\Delta l}{l}+(1-\alpha)\left(\frac{\Delta e}{e}\cdot \frac{\Delta r}{r}  \right) \right\}\cdot y\end{aligned}</script><p>$\Delta l$为人工减少率，可以看做员工死亡率；$\Delta e$为资本减少率 ，可以看做电气设备损坏与道路淹没情况的乘积。</p><h4 id="深度强化学习"><a href="#深度强化学习" class="headerlink" title="深度强化学习"></a>深度强化学习</h4><p>定义在时间<script type="math/tex">t</script>时，agent观测的到的状态是<script type="math/tex">S_t</script>，采取的动作是<script type="math/tex">a_t</script>，它可以获得一个奖励为<script type="math/tex">R_{S_t,S_{t+1}}^{a_t}</script>，并过渡到一个新的状态<script type="math/tex">S_{t+1}</script>，论文用的是Q-Learning算法，它学习一个动作-价值函数的方法，决定在当前状态下一步应采取哪个动作，<script type="math/tex">Q(S_t,a_t)</script>可以通过Q-Learning来更新：</p><script type="math/tex; mode=display">\begin{aligned}Q(S_t,a_t) \leftarrow Q(S_t,a_t )+\alpha\left[R_{S_t,S_{t+1}}^{a_t}+\gamma   \max_a ⁡Q(S_{t+1},a)-Q(S_t,a_t)\right ]\end{aligned}</script><p> 其中$\alpha(0 \leq \alpha \leq 1)$是学习率，$\gamma (0&lt; \gamma &lt;1)$是一个折扣率。作者采用多层神经网络进行深度强化学习，输入的状态包括影响公司行为控制的因素，例如灾难和交易环境以及整个供应链的交易状态。</p><h4 id="多智能体深度强化学习"><a href="#多智能体深度强化学习" class="headerlink" title="多智能体深度强化学习"></a>多智能体深度强化学习</h4><p>增强智能体间学习（RIAL，Reinforcement inter-agent learning），如下图所示：</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/1 RIAL.png" alt="RIAL"></p><p>在时间$t$时，agent 1使用Q-net（一种学习函数），同时使用环境的观测值<script type="math/tex">o_t</script>和agent 2之间的交互<script type="math/tex">m_{t-1}^2</script>作为学习数据。 之后，agent 2会以相同的方式学习。这样在学习过程中就可以将agents之间的相互作用考虑在内，不仅使公司的利润最大化，而且使所有代理商的利益最大化，这是一种多智能强化学习的合作关系设定。</p><h3 id="实验评估"><a href="#实验评估" class="headerlink" title="实验评估"></a>实验评估</h3><p>（a-1）采取随机action方法：前面一定时间内行为浪费，第10步才开始逐渐恢复。</p><p>（b-1）经过学习：大多数灾后行业从早期就恢复了生产，房地产（Real Estate）和服务业在大约两周内恢复了b-1灾前80％的状态。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/1 ab1.png" alt="ab1"></p><p>图（a-2），（b-2）显示了行业学习前后行为变化的比较。学习后，每个公司代理商都表现出行为方式的变化。灾后，许多公司已采取了有意义的行动，初期，确保供应商稳定，并恢复工作（恢复行为可以加快恢复）；在中期，倾向于有寻找客户，在后期，倾向于扩展业务。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/1 step.png" alt="step"></p><p>总的来说：这篇文章利用荒川河流提供的洪水模拟场景数据集模拟环境，伴随着环境的变化（洪灾信息、交易环境和供应链交易状态），agents采取相应的actions（5种）。基于此利用RIAL进行学习，并指导公司的行为。</p><h2 id="论文二：志愿者调度"><a href="#论文二：志愿者调度" class="headerlink" title="论文二：志愿者调度"></a>论文二：志愿者调度</h2><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/2 ab0.png" alt="洪水模拟"></p><p>这篇文章提出了一种启发式的多智能体强化学习调度算法ResQ，可以在动态环境中，有效地调度志愿营救者去救援受难者。ResQ有两个功能：</p><ol><li>利用社交网络数据快速识别出志愿者和受难者；</li><li>在复杂的动态环境中优化志愿者营救策略，ResQ算法通过一个启发式函数加快训练过程，该启发式函数通过识别一组特定于其他行为的行为来减少状态行为空间。</li></ol><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>当Harvey飓风于2017年8月25日登陆美国休斯敦部分地区，成千上万的受难人几乎同时打了911服务，由于线路资源有限，因此受难者则转向社交媒体寻求帮助，并用地址发布请求。同时，许多志愿者愿意提供救助服务，故需要协调，若不妥善协调，多名志愿者营救一人，便会造成人力浪费，因此需要为优化资源分配提供指导。下图为推特求救信息和志愿者愿意提供帮助的推文和受灾人员分布。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/2 sample.png" alt="sample tweet"></p><p>现实世界中的资源协调问题非常具有挑战性，原因有很多：</p><ol><li>样本量很小，尤其是在灾难初期，几乎没有可用数据时。任何决策支持系统都需要快速行动并迅速做出决策。</li><li>需要资源协调的现实环境是一个高度复杂的系统，具有多个不确定性。例如，志愿者和受难者的位置在动态变化，任意受难者的救援时间根据交通，道路封闭和紧急医疗等因素而变化，其中许多因素也在动态变化。</li><li>没有为灾害的调度问题建模的明确定义的目标函数，尤其是当受难者需要紧急护理或协作救援工作时。</li></ol><h3 id="数据-1"><a href="#数据-1" class="headerlink" title="数据"></a>数据</h3><ol><li><p>利用Twitter API爬取2017年8月23日至2017年9月5日共两周的Twitter数据，并基于SVM训练了3个分类器，第一个分类器区找出与Harvey飓风相关的Twitter，共173315条，第二和第三个分类器与从Harvey飓风相关的Twitter中找出志愿者和受难者的Twitter，共13953条和16535条。</p></li><li><p>获取地理坐标：如果推文具有GPS坐标，直接把GPS坐标当做地理坐标；如果没有，根据会结合其他信息来源来推断其位置，例如个人资料填写的位置，或者分析推文内容，借助<a href="http://archive.is/srm8P" target="_blank" rel="noopener">世界地名词典</a>数据库，找到位置名称和地理坐标。上图是选择休斯敦市一块边长为50英里的正方形区域，划分为<script type="math/tex">25 \times 25</script>个网格，将志愿者和受难者的地理位置坐标映射到正方形区域。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/2 grid.png" alt="sample tweet"></p></li></ol><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><ul><li><p>定义3.1：时间$t$时志愿者集合为<script type="math/tex">U_t=\{u_1,u_2,...,u_{N_t} \}</script>，总的志愿者数为$N$；</p></li><li><p>定义3.2：时间$t$时受难者集合为<script type="math/tex">V_t=\{v_1,v_2,...,v_{M_t} \}</script>，总的受难者数为$M$；</p></li><li><p>定义3.3：一个营救任务时间cost为<script type="math/tex">T=T(D)_{travel}+T_{load}+T_{shelter}</script>，$D$是该营救任务中志愿者和受害者的距离，<script type="math/tex">T_{load}</script>是营救时间（比如救上船），<script type="math/tex">T_{shelter}</script>把受难者送至距离营救地点最近的避难所。这里假设每个营救任务<script type="math/tex">T_{load}</script>和<script type="math/tex">T_{shelter}</script>都一样，只考虑<script type="math/tex">T(D)_{travel}</script>。</p></li><li><p>定义3.4：营救调度任务，随着时间$t$变化，<script type="math/tex">U_t</script>和<script type="math/tex">V_t</script>在变化，因此在时间$t$时，需要从<script type="math/tex">A_t</script>中找到一个最优的营救调度方案<script type="math/tex">X_t</script>，使得时间$t$时的营救总时间<script type="math/tex">C_t(X_t)</script>最小，<script type="math/tex">X_t</script>可以被写成一个<script type="math/tex">N_t \times M_t</script>矩阵。假设这里有<script type="math/tex">N_t</script>个志愿者去营救<script type="math/tex">M_t</script>的受难者，营救调度方案可以被表示为一个矩阵<script type="math/tex">X_t = (x_{ij})_{N_t M_t}</script>：</p><script type="math/tex; mode=display">\begin{aligned}x_{ij}=\begin{cases}1, i\text{被分配救援}j\\0, i\text{未被分配救援}j\\\end{cases}\end{aligned}</script><p>其中，$1\le i \le N, 1 \le j \le M$。</p></li></ul><p>营救调度问题被定义如下：</p><script type="math/tex; mode=display">\begin{aligned}\min_x C =\sum_{t=1}^{T}\sum_{i=1}^{N_t}\sum_{j=1}^{M_t}d_{ij}x_{ij}\\s.t.\begin{cases}\sum_{i=1}^{N_t}x_{ij} \le 1,j=1,...,M_t (j\text{最多分配一个志愿者来营救})\\\sum_{j=1}^{M_t}x_{ij}\ge 1,i=1,...,N_t(i\text{被分配的营救人数至少为}0\text{个})\\x_{ij} \in \{0,1\}\end{cases}\end{aligned}</script><p><strong>这里不知道作者有没有写错，感觉应该是至少为0，如果志愿者人数大于受难者人数，每个志愿者并不一定都要有营救任务。</strong></p><h4 id="ResQ：启发式多智能体强化学习（MARL）"><a href="#ResQ：启发式多智能体强化学习（MARL）" class="headerlink" title="ResQ：启发式多智能体强化学习（MARL）"></a>ResQ：启发式多智能体强化学习（MARL）</h4><p>MARL设置：agents是所有的志愿者，agents在这个网格环境里移动去救援受难者，换句话说，这是一个包含$N$个agent的Markov游戏<script type="math/tex">G=<N,S,A,P,R,\gamma></script>，$N$是agents的数量，$S$是states集合，$A$联合action空间，$P$是转移概率函数，$R$是reward函数，$\gamma$是折扣因子。</p><ul><li><p>Agent：$N_t$是时间$t$时agents数目；</p></li><li><p>State <script type="math/tex">s_t\in S</script>：<script type="math/tex">s_t^i</script>为在时间$t$时，可调度的志愿者$i$所在网格位置，此时全局状态为<script type="math/tex">s_t \in S</script>，$S$是一个有限集合。</p></li><li><p>Action <script type="math/tex">a_t\in A = A_1 \times ... \times A_{N_t}</script>：一个联合action <script type="math/tex">a_t=\{a_t^i\}_1^{N_t}</script>表示在时间$t$时为所有可调度志愿者的分配策略，<script type="math/tex">N_t</script>是所有可调度志愿者的数量，action空间<script type="math/tex">A_i</script>表示agent $i$下次迭代可采取的移动方向，移动方向可以被表示为4个离散action，即<script type="math/tex">k_{k=1}^4=\{up, down, right, right\}</script>，在时间$t$时，如果给出了一个agent $i$的state <script type="math/tex">s_t^i</script>和action <script type="math/tex">a_t^i</script>，我们可以计算出在时间<script type="math/tex">t+1</script>时，agent $i$的状态<script type="math/tex">s_{t+1}^i</script>，位于角落agent的action空间较小，policy $\pi$为一个序列actions，<script type="math/tex">\pi^*</script>为最优policy。</p></li><li><p>折扣因子$\gamma$：0到1之间，量化即时reward和未来reward重要性差异。</p></li><li><p>转移函数$P$：<script type="math/tex">S\times A \rightarrow [0,1]</script>：状态转移概率<script type="math/tex">p(s_{t+1}|s_t,a_t)</script>表示在当前状态<script type="math/tex">s_t \in S</script>采取联合action <script type="math/tex">a_t \in A_i</script>的情况下转移到<script type="math/tex">s_{t+1} \in S</script>的概率。</p></li><li><p>Reward函数$R_i \in R = S \times A \rightarrow(-\infty,+\infty)$：营救调度问题中的reward被定义为当agent在某个state采取action时来自环境的反馈。每个agent的奖励函数为$R_i$，并且同一位置的所有agent具有相同的reward函数。 第$i$个agent尝试最大化自己的期望折扣reward：</p><script type="math/tex; mode=display">\begin{aligned}R_t &= E(r_t^i + \gamma r_{t+1}^i + \cdots)\\&=E\left(\sum_{k=0}^{\infty}\gamma^k r_{k+1}^i \right)\\&=E(r_t^i + \gamma R_{t+1})\end{aligned}</script></li></ul><p>具体的reward设置作者没有描述。营救问题的目标是找到使总reward最大的最优策略$\pi^*$（agents的一系列动作）。引入状态值函数$V^{\pi}(s)$来评估不同policy的性能。$V^{\pi}(s)$表示从当前状态$s$采取policy $\pi$得到总折扣reward的期望：</p><script type="math/tex; mode=display">\begin{aligned}V^{\pi}(s) &= E_{\pi}(R_t|S=s_t)\\&=E_{\pi}\left(r_t+\gamma V^{\pi}(s')\right)\\&=r_t + \sum_{s'\in S}\gamma p^{\pi}(s'|s)V^{\pi}(s')\end{aligned}</script><p>根据贝尔曼优化公式，有：</p><script type="math/tex; mode=display">\begin{aligned}V^{\pi}(s) &= \max_{a \in A}r_t(s,a)+\sum_{s'\in S}\gamma P^{\pi}(s'|s)V^{\pi}(s')\end{aligned}</script><p>下面是 ResQ的营救调度算法，作者设计了一个启发式选择action的算法。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/2 ResQ.png" alt="sample tweet"></p><h3 id="实验评估-1"><a href="#实验评估-1" class="headerlink" title="实验评估"></a>实验评估</h3><p>对于分类器方法：用SVM与LR、KNN、CART做了分类性能比较，训练数据的Tweet标签应该是作者自己打的。</p><p>对于强化学习方法：对比的有如下几种，红框内为作者提出的方法：</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/2 Experiment.png" alt="sample tweet"></p><p>仿真环境：利用OpenAI Gym进行环境仿真，一个episode为志愿者营救完所有的受难者，没有过多的描述。</p><p>总体流程：作者先爬取两周的Tweet数据，然后区分每一天的志愿者和受难者，并根据推文获取坐并标映射为网格坐标，最后利用OpenAI Gym自定义仿真环境，基于该环境进行相关实验。</p><h2 id="论文三：节能协调控制"><a href="#论文三：节能协调控制" class="headerlink" title="论文三：节能协调控制"></a>论文三：节能协调控制</h2><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/31 ab1.png" alt="sample tweet"></p><p>这篇文章主发表在CISBAT 2019要为了解决用电高峰时期变得越来越频繁的问题，需求响应是指协调电力负载，使它们对价格信号做出反应并相互协调以减少用电高峰。作者使用多智能体深度确定性策略梯度（multi-agent deep deterministic policy gradient，DDPG），一种model-free的强化学习控制算法，它优于标准的Q-Learning强化学习，具有model-free和易操作的特点，作者在10座带有存储电量设备的建筑物模拟环境中实现了该控制器，并根据电价改变信号做出相应，相互协调来降低电费。控制器将室外温度，充电状态，一天中的时间（hour）和电价作为state。</p><h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><p>对于夏季（6月至8月）德克萨斯州奥斯汀的10座建筑物的制冷设备，每个建筑物有自己的存储电量设备，如何在花费更少的电力情况下，协调控制所有的建筑物（存电和放电）维持其恒定温度。</p><h3 id="数据-2"><a href="#数据-2" class="headerlink" title="数据"></a>数据</h3><p>这篇文章没有说，另一篇文章介绍这篇文章用到的仿真环境设计：</p><ul><li>论文题目：CityLearn v1.0: An OpenAI Gym Environment for Demand Response with Deep Reinforcement Learning</li><li>链接：<a href="https://dl.acm.org/doi/pdf/10.1145/3360322.3360998" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/3360322.3360998</a></li></ul><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/32 ab2.png" alt="sample tweet"></p><ul><li>项目地址：<a href="https://github.com/intelligent-environments-lab/CityLearn" target="_blank" rel="noopener">https://github.com/intelligent-environments-lab/CityLearn</a></li></ul><p>可以参考到用到的数据，应该是一样的，包括：</p><ul><li>建筑物时间序列信息：月、小时、该天的类型（8种）、夏令时状态、室内温度[C]，平均未满足制冷设定点差异[C]、室内相对湿度[％]、设备电力[kWh]、DHW加热[kWh]、制冷负荷[kWh]。</li><li>建筑物属性：建筑物类型、气候区、安装太阳板能量（kW）、热力泵信息、电热水器、降温水箱、DHW_Tank。</li><li>天气数据：室外干球温度[C]，室外相对湿度[％]，漫射太阳辐射[W / m2]，直接太阳辐射[W / m2]，6h预测室外干球温度[C]，12h预测室外干球温度[C]， 24h预测室外干球温度[C]，6h预测室外相对湿度[％]，12h预测室外相对湿度[％]，24h预测室外相对湿度[％]，6h预测散射太阳辐射[W / m2]，12h预测散射 太阳辐射[W / m2]，24h预测漫射太阳辐射[W / m2]，6h预测太阳直射辐射[W / m2]，12h预测太阳直射辐射[W / m2]，24h预测太阳直射辐射[W / m2]。</li><li>发电功率的历史记录：包括自1月1日00:00以来的小时数和小时数据：交流逆变器功率（W）。</li></ul><h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><p>强化学习（RL）可以用马尔可夫决策过程（MDP）形式化。MDP包含：一组states $S$，一组actions $A$，reward函数$R:A \times A$和状态之间的转移概率$P:S \times A \times S \in [0,1]$。策略$\pi$表示states与actions之间的映射$\pi : S \rightarrow A$，value函数$V(s)$是在状态$s$中开始并遵循策略$\pi$时agent的预期reward，即：</p><script type="math/tex; mode=display">V^{\pi}(s)=\sum_{a}\pi(s,a)\sum_{s'}p_{ss'}^a[R_{ss'}^a+\gamma V^{\pi}(s')]</script><p>其中$R_{ss’}^a$可以被表示为$r(s,a)$，即在采取action $a=\pi(s_k)$后，从当前state $s$到下一个state $s’$所获得的reward，$\gamma \in [0,1]$是折扣因子，为1表示未来reward与当前 reward同等重要。当模型 dynamic，即$P,R$未知且必须通过agent与环境的交互进行估算时，RL特别有用有两种方法可用于确定每个状态$V^{\pi}$值：</p><ul><li>一种model-based的方法，其中首先学习模型的奖励$R$和转移概率$P$，然后通过迭代求解上述方程式方程式来找到值。</li><li>一种是model-free的方法，agent可以学习与每个$(s,a)$对相关的值，而无需显式计算转换概率或期望reward。</li></ul><p>Q-learning由于其简单性而成为最广泛使用的model-free强化学习技术。对于有限状态集的任务，可以用一个表存储不同的state-action values，或者叫做Q-values，Q-values更新如下：</p><script type="math/tex; mode=display">Q(s,a)\leftarrow Q(s,a)+\alpha\left[r(s,a)+\gamma \max_a Q(s',a)-Q(s,a)\right]</script><p>其中$s’$是下一个state，$\alpha \in (0,1)$是学习率，对于$\alpha=0$，没有学习发生，而对于$\alpha=1$，在每次迭代中，先前的Q-value被新的Q-value完全覆盖。</p><h4 id="深度确定性策略梯度（Deep-deterministic-policy-gradient）"><a href="#深度确定性策略梯度（Deep-deterministic-policy-gradient）" class="headerlink" title="深度确定性策略梯度（Deep deterministic policy gradient）"></a>深度确定性策略梯度（Deep deterministic policy gradient）</h4><p>对于复杂环境中state和action是连续值的情况，表格式的Q-Learning无法应用，其他强化学习算法（例如深度确定性策略梯度（DDPG））更适合这些类型的问题。 DDPG是一种评价（critic）行为的方法，它使用两个DNN来概括state-action空间。actor网络将当前state映射到它认为最佳的action。 然后，critic网络通过将这些action以及state映射到Q值来critic这些action，如下图所示。 Q值表示在特定state下采取action预期reward累计总和。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/33 environment.png" alt="sample tweet"></p><p>通过拟合从Q-values更新公式，计算的Q值来更新critic网络，其中$\alpha=1$，并最小化Q值及其预测之间的损失，公式（3）。actor网络也被更新，公式（4）。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/34 eq.png" alt="sample tweet"></p><h4 id="多智能体协调（Multi-agent-coordination）"><a href="#多智能体协调（Multi-agent-coordination）" class="headerlink" title="多智能体协调（Multi-agent coordination）"></a>多智能体协调（Multi-agent coordination）</h4><p>每个建筑物的温度设定点是恒定的，由热泵（heat pump）给提供水箱冷却能量来给建筑物降温，若还不能达到恒定设定温度，热泵会提供额外的冷却能量给水箱，热泵会从电网消耗电力，电价随所有建筑物的总电力需求线性增加。因此，控制器（agent）的目的是通过避免同时消耗过多的电力和消耗较少的能量来降低其电力成本。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/35 madpg.png" alt="sample tweet"></p><p>每个建筑物都有其自己的RL-DDPG控制器，并且agent的数量与建筑物的数量（本例中为10个）相同。作者模拟了两个不同的RL控制器：DDPG控制器及其多智能体变体MADPG。在DDPG中，每个代理仅知道其自身的state和action，而在MADPG中，每个agent也都知道其他所有agent的state。State包括一天中所处的小时，室外温度，冷冻水箱的充电状态。action表述为每隔一小时存储或释放一次能量。</p><p>作者关注夏季（6月至8月）德克萨斯州奥斯汀的10座建筑物的制冷设备，模拟持续了大约40分钟（CPU：i7-6700 K 4.0 GHz，RAM：64.0 GB）。作者基于OpenAI环境设计了一个CitySim仿真环境，进行自己的实验。</p><h3 id="实验评估-2"><a href="#实验评估-2" class="headerlink" title="实验评估"></a>实验评估</h3><p>这篇文章与三个方法进行了对比，分别是DDPG、基于规则的控制器、基于手工优化的基于规则的控制器。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/36 experiment.png" alt="sample tweet"></p><p>总的来说，这篇文章和相关的另外一篇文章有开源数据和仿真环境设计的开源代码，可以用来参考学习。</p><h2 id="论文四：救护车重新部署策略"><a href="#论文四：救护车重新部署策略" class="headerlink" title="论文四：救护车重新部署策略"></a>论文四：救护车重新部署策略</h2><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/41 ab1.png" alt="sample tweet"></p><p>为了将可用的救护车重新部署到适当的救护站（需要考虑每个救护站的多个动态因素）去更好地接未来的患者，降低救护车接诊患者到医院的时间，文章提出了一种深度得分网络，将每一个救护站的动态因素平衡为一个得分，然后提出了一个深度强化学习框架来学习深度得分网络，基于学习到的深度评分网络，作者提供了一种有效的动态救护车重新部署算法。与基准模型相比，患者平均接诊时间节省约100秒（约20％），并在10分钟内患者的接诊率从0.786提高到0.838。</p><h3 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h3><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/42 fg1.png" alt="sample tweet"></p><p>上图（a）：（1）患者发出EMS（Emergency Medical Services）请求；（2）急救中心分配救护站；（3）救护站派救护车接患者；（4）接到患者后送至医院；（5）将救护车重新到救护站。</p><p>上图（b）：假设在1救护站的未来患者有3个，救护车部署到1会迅速将他们接走。目前来说，贪婪地调度算法可以取得很优的性能。</p><p>救护站的动态因素：（1）该救护站附近未来的预期患者数量；（2）当前救护站内已有救护车数量（考虑救护站容量）；（3）当前新的可用的救护车到达该救护站的时间；（4）其他救护车的状态，比如救护车2和4目的地医院离1号救护站更近，等它们送完患者再去1号救护站比立刻部署1号救护车到1号救护站更好。另外还有救护站覆盖范围等，动态因素比较复杂，难以仅仅通过手工规则来解决。</p><h3 id="数据-3"><a href="#数据-3" class="headerlink" title="数据"></a>数据</h3><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/43 fg2.png" alt="sample tweet"></p><p>中国天津市的EMS系统收集的数据，该数据由EMS请求记录，道路网络，救护站和医院组成，如下所示：</p><ul><li><p>EMS请求记录：EME请求记录包含来自患者的120呼叫。每条记录都包含一个时间戳，一个经纬度。从2014年10月1日到11月21日，收集了51天的EMS请求记录数据，其中包含23,549条记录。平均而言，每天约有462个EMS请求到达，每小时有约20个EMS请求。EMS请求的时空分布如图7所示。可以看出，EMS请求在空间和时间上是不平衡的。</p></li><li><p>救护站：天津有34个（地理位置由经度和纬度组成）的救护站。</p></li><li><p>医院：天津有41家医院，救护车可以将病人运送到这些医院。</p></li><li><p>道路网：该路网包含天津的道路信息，包括路顶点的经纬度，路段的长度和限速信息等。总共有99,007条路顶点和133,726条路段。在仿真环境中，作者使用道路网定义任意两个位置的实际行驶时间。</p></li></ul><p>作者的仿真环境是建立在先前别人仿真环境的基础上（对于地图，一般网格化），比如下面（这篇论文仿真参考的引用论文），更多的仿真设置并没有介绍。使用前31天EMS请求作为训练数据，通过深度强化学习算法来学习深度得分网络。后20天用作测试数据，以基于学习的深度得分网络评估重新部署算法。</p><h3 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h3><h4 id="深度得分网络（Deep-Score-Network）"><a href="#深度得分网络（Deep-Score-Network）" class="headerlink" title="深度得分网络（Deep Score Network）"></a>深度得分网络（Deep Score Network）</h4><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/45 fg4.png" alt="sample tweet"></p><p>深度得分网络如上图2所示，公式表示为：</p><script type="math/tex; mode=display">y_i = f(x_i:\theta)</script><p>包含一个输入层、两个隐藏层和一个输出层，$x_i$是每个救护站的动态因素，$\theta$是所有的参数，隐层都设为20，使用tanh激活函数，输出$y_i$为每个救护站的得分。</p><script type="math/tex; mode=display">x_i=(\lambda_i^1,...,\lambda_i^m,n_i,tt_i,tt_i^1,...,tt_i^k)</script><p>其中$(\lambda_i^1,…,\lambda_i^m),n_i,tt_i,(tt_i^1,…,tt_i^k)$为应用场景里介绍的救护站的4种动态因素。</p><h4 id="强化学习深度得分网络（Reinforcement-Learning-Deep-Score-Network）"><a href="#强化学习深度得分网络（Reinforcement-Learning-Deep-Score-Network）" class="headerlink" title="强化学习深度得分网络（Reinforcement Learning Deep Score Network）"></a>强化学习深度得分网络（Reinforcement Learning Deep Score Network）</h4><p>因为给定动态因素$x_i$，无法获取标签$y_i$，故不能用监督学习算法。</p><h5 id="强化学习框架"><a href="#强化学习框架" class="headerlink" title="强化学习框架"></a>强化学习框架</h5><p>可以将动态的救护车调度问题建模为强化学任务：</p><ul><li><p>Station：当一个救护车可用时，假设时间为$t$，可以获取当前的state $s_t$，由所有的救护站的动态因素组成，如下：</p><script type="math/tex; mode=display">s_t = (x_1,x_2,...,x_I)</script><p>其中$I$为救护站的总数。</p></li><li><p>Action：救护车的部署到那个救护站，$a_t=i$意味着当前可用救护车被部署到救护站$i$，如下：</p><script type="math/tex; mode=display">a_t=\{1,2,...,I\}</script></li></ul><ul><li><p>Transition：state转换时间间隔不定，只有要有新的救护车可用，自动转到下一个state。</p></li><li><p>Reward：<script type="math/tex">r_t=r(s_t,a_t)</script>为<script type="math/tex">s_t \rightarrow s_{t+1}</script>，接诊患者的时间小于10分钟的数量。比如<script type="math/tex">s_{t-1}\rightarrow s_t</script>有一个患者的接诊时间小于10分钟，因此<script type="math/tex">r_{t-1}=1</script>；<script type="math/tex">s_t \rightarrow s_{t+1}</script>有两个患者的接诊时间小于10，因此<script type="math/tex">r_t=2</script>；</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/46 fg5.png" alt="sample tweet"></p></li><li><p>Policy：作者利用策略网络实现策略<script type="math/tex">\pi_{\theta}(s_t,a_t)</script>，<script type="math/tex">\pi_{\theta}(s_t,a_t)</script>是一个概率函数。具体来说，给定当前状态<script type="math/tex">s_t=(x_1,x_2,...,x_I)</script>，将每个救护站的动态因素  输入到深度得分网络，等得到输出<script type="math/tex">y_i=f(x_i;\theta)</script>，组成<script type="math/tex">s_t</script>的嵌入输入到策略网络<script type="math/tex">\pi_{\theta}</script>，它只包含一组参数<script type="math/tex">\theta</script>，即不同的救护站共享一组参数<script type="math/tex">\theta</script>。这是因为作者为所有救护站学习一个得分网络，而不是为每个站点学习一个得分网络。得到所有的<script type="math/tex">y_i</script>，经过softmax函数输出部署到每个站点的概率。</p><script type="math/tex; mode=display">\pi_{\theta}(s_t,a_t=i)=\frac{\exp(f(x_i;\theta))}{\sum_{i'=1}^I\exp(f(x_{i'};\theta))}</script><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/47 fg6.png" alt="sample tweet"></p></li></ul><h5 id="用策略梯度学习参数-theta-（Learning-theta-with-Policy-Gradient）"><a href="#用策略梯度学习参数-theta-（Learning-theta-with-Policy-Gradient）" class="headerlink" title="用策略梯度学习参数$\theta$（Learning $\theta$  with Policy Gradient）"></a>用策略梯度学习参数$\theta$（Learning $\theta$  with Policy Gradient）</h5><p><strong>目标</strong>：学习一个最优策略网络<script type="math/tex">\pi_{\theta}</script>，使得在给定任何state <script type="math/tex">s</script>的情况下，通过遵循策略<script type="math/tex">\pi_{\theta}</script>，agent都能最大化长期折扣reward的期望，即在给定的时间阈值内，接诊患者人数最多。目标函数形式化定义为：</p><script type="math/tex; mode=display">\max_{\theta}J(\theta)=\mathbb{E}_{s \sim \pi_{\theta}}[v(s)]</script><p>其中，<script type="math/tex">v(s)</script>是遵循策略<script type="math/tex">\pi_{\theta}</script>并从state <script type="math/tex">s</script>开始，获得的长期折扣reward的期望；<script type="math/tex">s \sim \pi_{\theta}</script>表示从任意随机状态开始，state <script type="math/tex">s</script>从策略<script type="math/tex">\pi_{\theta}</script>采样而得，<script type="math/tex">v_(s)</script>表述为：</p><script type="math/tex; mode=display">v(s)=\mathbb{E}[r_t + \gamma r_{t+1} + \gamma^2 r_{t+2} + \cdots|s=s_t]</script><p>其中<script type="math/tex">\gamma=[0,1]</script>是未来reward的折扣率（例如<script type="math/tex">\gamma=0.99</script>）。<script type="math/tex">v(s)</script>也称为state value。另外对于任何state <script type="math/tex">s</script>和action <script type="math/tex">a</script>，可以遵循<script type="math/tex">q(s,a)</script>表示的策略<script type="math/tex">\pi_{\theta}</script>，计算长期折扣reward的期望：</p><script type="math/tex; mode=display">q(s,a)=\mathbb{E}[r_t + \gamma r_{t+1} + \gamma^2 r_{t+2} + \cdots|s=s_t,a=a_t]</script><p>其中，<script type="math/tex">q(s,a)</script>称为state-action value，<script type="math/tex">v(s)</script>和<script type="math/tex">q(s,a)</script>关系如下式和下图：</p><script type="math/tex; mode=display">v(s)=\sum_{a\in A}\pi_{\theta}(s,a)q(s,a)</script><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/48 fg7.png" alt="sample tweet"> </p><p><strong>梯度</strong>：$J(\theta)$ 对$\theta$的梯度和梯度更新（最大化目标）为：</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta}J(\theta) &=\mathbb{E}_{s \sim \pi_{\theta}}[\nabla_{\theta} \log \pi_{\theta}(s,a)\cdot q(s,a)]\\\theta &\leftarrow \theta + \alpha \cdot \nabla_{\theta}J(\theta)\end{aligned}</script><p>$\alpha$为0.005。</p><p><strong>挑战</strong>：由于EMS环境的复杂性，无法获得上述期望，因此采用蒙特卡洛方法随机采样来解决。</p><h5 id="动态重新部署算法（Dynamic-Redeployment-Algorithm"><a href="#动态重新部署算法（Dynamic-Redeployment-Algorithm" class="headerlink" title="动态重新部署算法（Dynamic Redeployment Algorithm"></a>动态重新部署算法（Dynamic Redeployment Algorithm</h5><p><strong>算法1</strong> 是用强化学习学习深度得分网络的参数$\theta$。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/49 fg8.png" alt="sample tweet"></p><p><strong>算法2</strong> 是部署，计算每一个救护站的得分，选择得分最大的救护站。</p><p><img src="/2021/01/26/%E5%9B%9B%E7%AF%87%E8%AE%BA%E6%96%87-%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%87%AA%E7%84%B6%E7%81%BE%E5%AE%B3%E5%92%8C%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/50 fg9.png" alt="sample tweet"></p><script type="math/tex; mode=display">i^*=\arg \max_i {y_i = f(x_i;\theta)}</script><h3 id="实验评估-3"><a href="#实验评估-3" class="headerlink" title="实验评估"></a>实验评估</h3><p>选择了6个baseline，RS（随机选择一个救护站）、NS（最近的救护站）、ERTM、MEXCLP和DMEXCLP，有两个评估指标。其余包括其他的分析：解释部署方法的有效性、分析模型部署后推断很快、训练收敛性能分析、用深度得分网络的必要性、考虑救护站所有动态因素的必要性、讨论一些参数的影响（救护站附近的请求个数和救护车数量）、患者数量的影响、方法的鲁棒性等等。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>四篇文章总结如下：</p><div class="table-container"><table><thead><tr><th>背景</th><th>数据</th><th>方法</th><th>仿真</th></tr></thead><tbody><tr><td>日本荒川河流，公司交易链恢复</td><td>洪水模拟数据(来自政府)，真实的公司信息数据</td><td>多智能体深度强化学习</td><td>利用政府提供的工具和手册仿真</td></tr><tr><td>美国Harvey飓风，志愿者调度问题</td><td>爬取Tweet数据，设计分类器，识别出志愿者和受难者，确定地理位置信息</td><td>启发式多智能体强化学习ResQ</td><td>基于OpenAI Gym自定义</td></tr><tr><td>对夏季10座建筑物的制冷设备协同调节</td><td>夏季（6月至8月）德克萨斯州奥斯汀的10座建筑物的制冷设备信息，天气等信息</td><td>多智能体变体MADPG</td><td>基于OpenAI Gym自定义，数据和代码开源</td></tr><tr><td>天津市救护车重新部署</td><td>救护站、医院、道路网和EMS请求数据</td><td>利用深度强化学习框架来学习深度得分网络，根据得分进行部署</td><td>未说明</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> 多智能体强化学习 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 自然灾害 </tag>
            
            <tag> 智慧城市 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux知识点笔记</title>
      <link href="/2020/11/12/Linux%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/11/12/Linux%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>这篇博客主要记录自己在使用Linux服务器时，常使用的一些命令以及需要掌握的知识。其中部分内容参考了一些博主的总结，并附上了参考链接，后续内容会根据自己的学习历程持续更新。</p><a id="more"></a><h2 id="top-命令"><a href="#top-命令" class="headerlink" title="top 命令"></a>top 命令</h2><p>top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。为了显示详细的进行命令，这里输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -c</span><br></pre></td></tr></table></figure><p><img src="/2020/11/12/Linux%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%94%E8%AE%B0/top-c命令截图.png" alt="top-c命令截图"></p><p>下面进行分析：</p><h3 id="第一行-系统信息"><a href="#第一行-系统信息" class="headerlink" title="第一行  系统信息"></a>第一行  系统信息</h3><div class="table-container"><table><thead><tr><th>显示信息</th><th>含义</th></tr></thead><tbody><tr><td>03:02:19</td><td>系统时间</td></tr><tr><td>up 175 days，21:01</td><td>已运行时间</td></tr><tr><td>1 user</td><td>当前登录用户，包含系统用户</td></tr><tr><td>47.94，36.10，30.82</td><td>负载均衡-load average，即1，5，15分钟的负载情况</td></tr></tbody></table></div><p>负载均衡数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</p><h3 id="第二行-进程信息"><a href="#第二行-进程信息" class="headerlink" title="第二行 进程信息"></a>第二行 进程信息</h3><div class="table-container"><table><thead><tr><th>显示信息</th><th>含义</th></tr></thead><tbody><tr><td>Task：794 total</td><td>总进程数</td></tr><tr><td>6 running</td><td>正在运行的进程数</td></tr><tr><td>389 sleeping</td><td>睡眠的进程数</td></tr><tr><td>4 stopped</td><td>停止的进程数</td></tr><tr><td>109  zombie</td><td>僵尸进程数</td></tr></tbody></table></div><h3 id="第三行-CPU使用情况"><a href="#第三行-CPU使用情况" class="headerlink" title="第三行 CPU使用情况"></a>第三行 CPU使用情况</h3><div class="table-container"><table><thead><tr><th>显示信息</th><th>含义</th></tr></thead><tbody><tr><td>Cpu(s)：20.2%us</td><td>CPU占用率-用户进程占cpu百分比，user space</td></tr><tr><td>7.1%sy</td><td>系统占用CPU百分比，sysctl</td></tr><tr><td>0.0%ni</td><td>改变过优先级的进程占CPU百分比</td></tr><tr><td>72.6%id</td><td>空闲CPU百分比，idolt</td></tr><tr><td>0.0%wa</td><td>IO等待占用CPU百分比，wait</td></tr><tr><td>0.0%hi</td><td>硬中断占用CPU的百分比，Hardware IRQ</td></tr><tr><td>0.0%si</td><td>软中断占用CPU的百分比，Software Interrupts</td></tr><tr><td>0.0%st</td><td>窃取时间，与虚拟化有关，你的虚拟机中系统花了百分之多少等待得到真正的cpu资源，steal time</td></tr></tbody></table></div><h3 id="第四行-内存状态"><a href="#第四行-内存状态" class="headerlink" title="第四行 内存状态"></a>第四行 内存状态</h3><div class="table-container"><table><thead><tr><th>显示信息</th><th>含义</th></tr></thead><tbody><tr><td>522616916k total</td><td>内存总量</td></tr><tr><td>380851436k used</td><td>内存使用量</td></tr><tr><td>141765480k free</td><td>内存空闲量</td></tr><tr><td>1814552k buffers</td><td>缓存的内存量</td></tr></tbody></table></div><h3 id="第五行-swap交换分区信息"><a href="#第五行-swap交换分区信息" class="headerlink" title="第五行 swap交换分区信息"></a>第五行 swap交换分区信息</h3><div class="table-container"><table><thead><tr><th>显示信息</th><th>含义</th></tr></thead><tbody><tr><td>0k total</td><td>交换分区总量</td></tr><tr><td>0k used</td><td>交换分区使用量</td></tr><tr><td>0k free</td><td>交换分区空闲量</td></tr><tr><td>107261708k cached</td><td>缓冲的交换分区总量</td></tr></tbody></table></div><p>备注：</p><ul><li><p>可用内存 = free + buffer + cached</p></li><li><p>对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。</p></li><li><p>第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，</p></li><li><p>第四行中空闲内存总量（free）是内核还未纳入其管控范围的数量。</p></li><li>纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。</li></ul><h3 id="第六行-空行"><a href="#第六行-空行" class="headerlink" title="第六行 空行"></a>第六行 空行</h3><h3 id="第七行-各进程（任务）的状态监控"><a href="#第七行-各进程（任务）的状态监控" class="headerlink" title="第七行 各进程（任务）的状态监控"></a>第七行 各进程（任务）的状态监控</h3><div class="table-container"><table><thead><tr><th>显示信息</th><th>含义</th></tr></thead><tbody><tr><td>PID</td><td>进程id</td></tr><tr><td>USER</td><td>进程所有者</td></tr><tr><td>PR</td><td>进程优先级</td></tr><tr><td>NI</td><td>nice值。越小优先级越高，最小-20，最大20（用户设置最大19）</td></tr><tr><td>VIRT</td><td>进程使用的虚拟内存总量，单位kb，VIRT=SWAP+RES</td></tr><tr><td>RES</td><td>进程使用的、未被换出的物理内存大小，单位kb，RES=CODE+DATA</td></tr><tr><td>SHR</td><td>共享内存大小，单位kb</td></tr><tr><td>S</td><td>进程状态，D = 不可中断的睡眠状态，R = 运行，S = 睡眠，T = 跟踪/停止，Z = 僵尸进程</td></tr><tr><td>%CPU</td><td>进程占用CPU百分比</td></tr><tr><td>%MEM</td><td>进程占用物理内存百分比</td></tr><tr><td>TIME+</td><td>进程运行时间</td></tr><tr><td>COMMAND</td><td>进程命令</td></tr></tbody></table></div><p>备注：</p><ul><li>PR 越低，优先级越高，PRI(new)=PRI(old)+nice；改变优先级：进入top后按”r”–&gt;输入进程PID–&gt;输入nice值</li></ul><h3 id="top后使用的命令"><a href="#top后使用的命令" class="headerlink" title="top后使用的命令"></a>top后使用的命令</h3><div class="table-container"><table><thead><tr><th>命令</th><th>含义</th></tr></thead><tbody><tr><td>P</td><td>以占据CPU百分比排序</td></tr><tr><td>M</td><td>以占据内存百分比排序</td></tr><tr><td>T</td><td>以累积占用CPU时间排序</td></tr><tr><td>q</td><td>退出top查看页面命令</td></tr><tr><td>s</td><td>修改刷新时间间隔。按下s键，然后按下数字，即可修改刷新时间间隔为你输入的数字，单位为秒。例如：按下s键，在按数字1键，即可实现每秒刷新一次</td></tr><tr><td>k</td><td>终止指定的进程。按下k键—&gt;再输入要杀死的进程的pid—&gt;按enter键—&gt;(选择信号类型，以数字标示，默认15为杀死)本步可省略按enter键（常用为-9）</td></tr></tbody></table></div><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><p><a href="https://www.cnblogs.com/ftl1012/p/top.html" target="_blank" rel="noopener">Linux top命令详解</a></p></li><li><p><a href="https://www.jianshu.com/p/078ed7895b0f" target="_blank" rel="noopener">top命令详解</a></p></li></ul><h2 id="孤儿进程和僵尸进程"><a href="#孤儿进程和僵尸进程" class="headerlink" title="孤儿进程和僵尸进程"></a>孤儿进程和僵尸进程</h2><p>在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束。当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。</p><ul><li><p><strong>孤儿进程：</strong>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。每当出现 孤儿进程的时候，内核会把孤儿进程的父进程设为init进程(进程号为1)，并由init进程对它们完成状态收集工作。<strong>因此孤儿进程不会有什么危害。</strong></p></li><li><p><strong>僵尸进程：</strong>一个进程使用fork创建子进程，如果子进程退出，内核释放该子进程所有的资源，而父进程并没有调用wait()或waitpid()获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程，比如会一直占用进程号等。若一个父进程，定期产生一个子进程，但对子进程退出之后的事一概不问，便产生了大量僵尸进程。我们可以通过kill命令杀死僵尸进程 ，但僵尸进程并非问题根源，罪魁祸首是产生监视进程的父进程，因此我们只需要kill掉那个父进程，僵尸进程便会由init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，进而完成状态收集工作。<strong>因此僵尸进程是有危害的。</strong></p></li></ul><h3 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://www.cnblogs.com/Anker/p/3271773.html" target="_blank" rel="noopener">孤儿进程与僵尸进程总结</a></li></ul><h2 id="pip和pip3命令"><a href="#pip和pip3命令" class="headerlink" title="pip和pip3命令"></a>pip和pip3命令</h2><p>pip3只有在安装了python3.x之后才会有，比如安装flask库，分情况说明：</p><ul><li>此时，若安装了python2.x和python3.x：<ul><li><code>pip install flask</code>，会安装在目录<code>python2.x/site-packages/</code>下；</li><li><code>pip3 install flask</code>，会安装在目录<code>python3.x/site-packages/</code>下；</li><li>若使用python3.x执行程序，那么就不能<code>import python2.x/site-packages/</code>来使用python2.x的库。</li></ul></li><li>只安装python2.x：<ul><li>只能用<code>pip install flask</code>命令安装，会安装在目录<code>python2.x/site-packages/</code>下；</li></ul></li><li>只安装了python3.x：<ul><li><code>pip install flask</code>和<code>pip3 install flask</code>，都会安装在目录<code>python3.x/site-packages/</code>下；</li></ul></li></ul><h2 id="Vim命令"><a href="#Vim命令" class="headerlink" title="Vim命令"></a>Vim命令</h2><p>Vim有四种模式：</p><ul><li>正常模式：可以使用快捷键命令，或按:输入命令行。</li><li>插入模式：可以输入文本，在正常模式下，按i、a、o等都可以进入插入模式。</li><li>可视化模式：正常模式下按v可以进入可视模式， 在可视模式下，移动光标可以选择文本。按V进入可视行模式， 总是整行整行的选中。ctrl+v进入可视块模式。</li><li>替换模式：正常模式下，按R进入。</li></ul><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p>正常模式下：</p><ul><li>/something: 在后面的文本中查找something。</li><li>?something: 在前面的文本中查找something。</li></ul><h3 id="参考-2"><a href="#参考-2" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/51440836" target="_blank" rel="noopener">史上最全的Vim命令</a></li></ul><h2 id="git命令"><a href="#git命令" class="headerlink" title="git命令"></a>git命令</h2><h3 id="克隆"><a href="#克隆" class="headerlink" title="克隆"></a>克隆</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/KunchiLiu/deep_pay</span><br></pre></td></tr></table></figure><h3 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">"aa"</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><h3 id="本地修改，pull最新"><a href="#本地修改，pull最新" class="headerlink" title="本地修改，pull最新"></a>本地修改，pull最新</h3><p>本次修改后无法pull，应先还原，再pull</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout .</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure><h3 id="删除已push的文件-文件夹"><a href="#删除已push的文件-文件夹" class="headerlink" title="删除已push的文件/文件夹"></a>删除已push的文件/文件夹</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git rm -r --cached notes.md    </span><br><span class="line">git commit -m <span class="string">"delete notes.md"</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><h3 id="强制覆盖"><a href="#强制覆盖" class="headerlink" title="强制覆盖"></a>强制覆盖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git  fetch -all</span><br><span class="line">git reset --hard origin/master</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure><h3 id="版本回退"><a href="#版本回退" class="headerlink" title="版本回退"></a>版本回退</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span></span><br><span class="line">git reset --hard 27b845b2d12c4fb8428b84a6a65841a2afe0530a</span><br></pre></td></tr></table></figure><h2 id="kill命令"><a href="#kill命令" class="headerlink" title="kill命令"></a>kill命令</h2><h3 id="kill所有python进程"><a href="#kill所有python进程" class="headerlink" title="kill所有python进程"></a>kill所有python进程</h3><ul><li><p>killall方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">killall python</span><br></pre></td></tr></table></figure></li><li><p>pkill方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pkill python</span><br></pre></td></tr></table></figure></li><li><p>ps方式（脚本）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep <span class="string">"python train_mini_batch.py"</span> | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span> | xargs <span class="built_in">kill</span> -9</span><br></pre></td></tr></table></figure></li></ul><div class="table-container"><table><thead><tr><th>命令</th><th>含义</th></tr></thead><tbody><tr><td>ps -ef</td><td>是Red Hat 里查看所有进程的命令。检索结果作为下一条命令的输入。</td></tr><tr><td>grep “python train_mini_batch.py”</td><td>是所有含有关键字“LOCAL=NO”的进程。</td></tr><tr><td>grep -v grep</td><td>从列出的进程中去除含有关键字“grep”的进程。</td></tr><tr><td>awk ‘{print $2}’</td><td>列出检索出所有的进程号PID。</td></tr><tr><td>xargs kill -9</td><td>xargs命令是用来把前面命令的输出结果（PID）作为“kill -9”命令的参数，并执行该令。</td></tr></tbody></table></div><h3 id="参考-3"><a href="#参考-3" class="headerlink" title="参考"></a>参考</h3><ul><li><p><a href="https://blog.csdn.net/qq_39390545/article/details/103205943" target="_blank" rel="noopener">linux下3种高效Kill掉所有python进程的方法（包括编写运行脚本 .sh）</a></p></li><li><p><a href="https://cloud.tencent.com/developer/article/1336858" target="_blank" rel="noopener">linux 批量杀死多个进程 kill</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>社区发现方法调研-统计机器学习</title>
      <link href="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>这次调研主要参考了2017年的一篇综述《Network Community Detection: A Review and Visual Survey》，文中主要介绍了基于统计推断和机器学习的社区检测方法，还包括一些公开数据集和评估指标等，这里只介绍一些传统方法，更多可以看原论文和参考中第二个链接。</p><a id="more"></a><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/title.png" alt="标题"></p><p>社区结构是复杂网络中广泛研究的结构特征，网络中的社区是节点的密集组合，它们在组内彼此紧密耦合，而与网络中其余的顶点松散耦合。社区检测在理解复杂网络的功能方面起着关键作用。文章将社区发现算法分为四类：传统方法、基于模块度的方法、重叠社区检测方法和动态社区检测方法。</p><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/approaches.png" alt="方法分类"></p><p>这里首先介绍一下模块度的概念，然后五种算法，分别是传统方法中GN算法，基于模块度方法中的FN和Louvai算法，标签传播算法，以及InfoMap算法。</p><h2 id="模块度概念（Modularity）"><a href="#模块度概念（Modularity）" class="headerlink" title="模块度概念（Modularity）"></a>模块度概念（Modularity）</h2><ul><li>Network Community Detection: A Review and Visual Survey</li></ul><p>模块度可以用来衡量网络中社区的划分是否优良，它的物理含义是社区内节点的连边数与网络随机情况下社区内的边数之差，占网络总边数的比例，即网络中社区内部实际边的比例减去社区内部期望边的比例。一个好的划分结果其表现形式是：在社区内部的节点相似度较高，而在社区外部节点的相似度较低）。关于模块度的定义，文中列举了模块度定义的更新迭代：</p><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/modularity.png" alt="模块度发展"></p><p>下面是一种最常用的模块度定义公式：</p><script type="math/tex; mode=display">\begin{aligned}Q &=\frac{1}{2m}\sum_{i,j}\left [A_{ij}-\frac{k_i k_j}{2m}\right]\delta\left(c_i,c_j \right)\\\delta\left(c_i,c_j \right) &= \begin{cases} 1& c_i=c_j\\0 &c_i \neq c_j\end{cases}\end{aligned}</script><p>其中，<script type="math/tex">A_{ij}</script>表示节点<script type="math/tex">i</script>与节点$j$之间边的权重，网络不是带权图时，表示连边数；<script type="math/tex">k_i=\sum_{j} A_{ij}</script>表示所有与节点$i$相连的边的权重之和（度数）；<script type="math/tex">c_i</script>表示节点$i$所属的社区；<script type="math/tex">m=\frac{1}{2}\sum_{ij}A_{ij}</script>表示所有边的权重之和（边数），这里重复计算了边数，所以会除以2。$Q$的取值范围是<script type="math/tex">\left[-\frac{1}{2},1\right)</script>。</p><ul><li>当图中只有两个节点，把两个节点各分为1个社区，那么$Q$取值为$-\frac{1}{2}$；</li><li>$Q$的上限为1，越接近这个值，就说明社区结构越明显；</li><li>在实际网络中，$Q$值常位于0.3和0.7之间。</li></ul><p>公式中<script type="math/tex">A_{ij}-\frac{k_i k_j}{2m}=A_{ij}-k_i\frac{k_j}{2m}</script>，节点$j$连接到任意一个节点的概率是<script type="math/tex">\frac{k_j}{2m}</script>，现在节点$i$的度数为<script type="math/tex">k_i</script>，因此随机情况下节点$i$与$j$连边的为权重为$A_{ij}$，接下来将该公式进行如下简化：</p><script type="math/tex; mode=display">\begin{aligned}Q &= \frac{1}{2m}\sum_{i,j}\left [A_{ij}-\frac{k_i k_j}{2m}\right]\delta\left(c_i,c_j \right)\\ &= \frac{1}{2m}\left [\sum_{i,j}A_{ij}-\frac{\sum_i k_i \sum_j k_j}{2m}\right]\delta\left(c_i,c_j \right)\\ &=\frac{1}{2m} \sum_c \left[ \sum{in} - \frac{\left(\sum{tot}\right)^2}{2m} \right]\\ &= \sum_c \left[ \frac{\sum{in}}{2m} - \left(\frac{\sum{tot}}{2m}\right)^2 \right]\\\end{aligned}</script><p>其中$\frac{\sum{in}}{2m}$表示社区内实际边的比例，$\left(\frac{<br>\sum{tot}}{2m}\right)^2$表示随机情况下，社区内期望边的比例。</p><h2 id="分裂方法"><a href="#分裂方法" class="headerlink" title="分裂方法"></a>分裂方法</h2><h3 id="GN算法-2002"><a href="#GN算法-2002" class="headerlink" title="GN算法-2002"></a>GN算法-2002</h3><ul><li>Community structure in social and biological networks</li></ul><p>Girvan-Newman算法（2002）是一种基于介数的社区发现算法，同时，他们二人还提出用边介数来标记每条边对网络连通性的影响。GN算法基本思想是根据边介数（edge betweenness）从大到小的顺序不断的将边从网络中移除直到整个网络分解为各个社区。每条边的边介数可以理解为网络中通过这条边的最短路径数目。GN算法的基本流程如下：</p><ol><li>计算网络中所有边的边介数；</li><li>找到边介数最高的边并将它从网络中移除，若不唯一，则随机选一条断开或同时断开；</li><li>重新计算网络中各条边的边介数，重复步骤2，直到每个节点成为一个独立的社区为止，即网络中没有边存在。</li></ol><p>可以根据想要划分的社区个数进行划分，或者根据$Q$值进行划分。</p><h2 id="基于模块度的方法"><a href="#基于模块度的方法" class="headerlink" title="基于模块度的方法"></a>基于模块度的方法</h2><p>基于模块度的社区发现算法，都是以最大模块度$Q$为目标进行的。快速算法FN和快速模块度最大化算法Louvain的原理非常相似，二者都是基于局部模块度最大化来进行的。</p><h3 id="快速算法FN-2004"><a href="#快速算法FN-2004" class="headerlink" title="快速算法FN-2004"></a>快速算法FN-2004</h3><ul><li>Fast algorithm for detecting community structure in network</li></ul><p>FN核心算法思想（2004）：</p><ol><li>去掉网络中所有的边，网络的每个节点都作为单独的一个社区；</li><li>网络中的每个连通部分作为一个社区，将还未加入网络的边重新加回网络，每次加入一条边，如果加入网络的边连接了两个不同的社区，则合并两个社区，并计算形成新社区划分的模块度增量，选择使模块度增量最大的两个社区进行合并；</li><li>如果一直能够找到使得模块度增大的合并，则返回步骤（2）继续迭代，否则转到步骤（4）；</li><li>遍历每种社区划分对应的模块度值，选取模块度最大的社区划分作为网络的最优划分。</li></ol><h3 id="快速模块度最大化算法Louvain-2004"><a href="#快速模块度最大化算法Louvain-2004" class="headerlink" title="快速模块度最大化算法Louvain-2004"></a>快速模块度最大化算法Louvain-2004</h3><ul><li>Fast unfolding of communities in large networks</li></ul><p>Louvain算法思想（2008），分为两个阶段：</p><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/louvain.png" alt="louvain算法"></p><p>第一个阶段：</p><ol><li>首先，将网络中每个节点看做一个社区，每个社区内的权重为0；</li><li>然后，对于每个节点$i$，依次尝试把节点$i$分配到每个邻居节点所在的社区，计算分配前后模块度的变化$\Delta Q$，并记录$\Delta Q$最大的那个邻居节点，如果$\max \Delta Q &gt; 0$，则把节点$i$分配给$\Delta Q$最大的那个邻居节点所在的社区，否则不变；</li><li>最后，重复2，直到所有节点的所属社区不再变化；</li></ol><p>$\Delta Q$公式如下：</p><script type="math/tex; mode=display">\begin{aligned}\Delta Q &= \left[ \frac{\sum{in}+k_{i,in}}{2m} - \left(\frac{\sum{tot}+k_i}{2m}\right)^2 \right] -\left[\frac{\sum{in}}{2m} - \left(\frac{\sum{tot}}{2m}\right)^2-\left(\frac{k_i}{2m}\right)^2\right]\end{aligned}</script><p>其中$k_{i,in}$是社区（比如$c$）内部节点与节点$i$的连边权重之和，这里要乘以2；$\Delta Q$分了两部分，前半部分是把节点$i$加入到社区$c$后的模块度，后半部分是将节点$i$作为一个独立社区时，社区$c$的模块度；在实现$\Delta Q$时可以简化：</p><script type="math/tex; mode=display">\begin{aligned}\Delta Q &= \left[ \frac{k_{i,in}}{2m} - \frac{\sum{tot}\cdot k_i}{2m^2} \right]\end{aligned}</script><p>第二个阶段：</p><ol><li>对网络进行压缩，将所有在同一个社区的节点压缩成一个新的节点，社区内节点之间边的权重转化为新节点自连接的权重，社区间边的权重转化为新节点之间边的权重。</li><li>重复第一个阶段，直到整个网络的模块度不再发生变化。</li></ol><p>该方法的论文中提到第一阶段的第2步，遍历节点的顺序对划分社区结果有一定影响，但差距不大，只是会影响算法的时间效率。该方法可以处理无向带权图，官网说可以修改之后应用到有向图。</p><h2 id="动态方法"><a href="#动态方法" class="headerlink" title="动态方法"></a>动态方法</h2><h3 id="LPA-标签传播算法-2007"><a href="#LPA-标签传播算法-2007" class="headerlink" title="LPA-标签传播算法-2007"></a>LPA-标签传播算法-2007</h3><ul><li>Near linear time algorithm to detect community structures in large-scale networks</li></ul><p>Label Propagation（LPA）是一种基于标签传播的局部社区划分算法。对于网络中的每一个节点，在初始阶段，LPA算法对于每一个节点都会初始化一个唯一的一个标签。每一次迭代都会根据与自己相连的节点所属的标签改变自己的标签，更改的原则是选择与其相连的节点中所属标签最多的社区标签为自己的社区标签，这就是标签传播的含义了。随着社区标签不断传播。最终，连接紧密的节点将有共同的标签。</p><p>LPA的基本思想是每个节点的标签应该和大多数邻居标签相同（bagging思想），给每个节点添加标签以表示它所属的社区，并通过传播使得社区内部拥有相同的标签。可以看出，LPA与K-means本质很相似。在LPA每轮迭代中，给节点划分社区取决于其邻居中累加权重最大的标签（无权图则每个节点对应标签weight=1），而K-means则是计算每个类中心（社区）到当前节点的距离，并将节点划分到最近的类中。但是二者还是有区别的：</p><ol><li>K-means是基于欧式空间计算节点向量间的距离，而LPA则是根据节点间的”共有关系“以及“共有关系的强弱程度”来度量度量节点间的距离；</li><li>K-means中节点处在欧式空间中，它假设所有节点之间都存在“一定的关系”，不同的距离体现了关系的强弱。但是 LPA 中节点间只有满足“某种共有关系”时，才存在节点间的边，没有共有关系的节点是完全隔断的，计算邻居节点的时候也不会计算整个图结构，而是仅仅计算和该节点有边连接的节点，从这个角度看，LPA 的这个图结构具有更强的社区型；</li><li>LPA无需指定聚类社区的个数，因为它可以看做一个彻底的自下而上方法，而K-means则需要指定聚类的类别个数。</li></ol><p>算法描述：</p><ol><li>先给每个节点分配对应标签，即节点1对应标签1，节点$i$对应标签$i$，也可以用节点id当做初始标签； </li><li>遍历$N$个节点，找到对应节点邻居，获取此节点邻居标签，找到出现次数最大标签，若出现次数最多标签不止一个，则随机选择一个标签替换成此节点标签；</li><li>若本轮标签重标记后，节点标签不再变化（或者达到设定的最大迭代次数），则迭代停止，否则重复第2步。</li></ol><p>标签传播方式：</p><ol><li><p>同步更新-synchronous</p><p>当前迭代中，是基于邻居的上一次迭代中的标签来更新节点的新标签:</p></li><li><p>异步更新-asynchronous</p><p>节点的标签并不区分当前迭代和上一次迭代，永远都只使用节点最新的标签。 论文中是推荐使用异步更新方式的，主要原因在于同步更新可能出现标签的交替振荡而无法达到稳定态，这种情况很容易在星状图中出现，如下：</p><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/synchronous.png" alt="同步更新-星状图"></p></li></ol><p>如果有先验知识的话，可以给网络中的节点标上先验的标签，然后其他的节点不标标签，这样也可以最后达到社区划分的效果。新浪微博似乎就是走的这个套路，首先会有一些用户打上了标签，然后让这些标签在整个网络中扩散出去，最终的效果就是大部分人都被打上标签。</p><h3 id="InfoMap算法-2008"><a href="#InfoMap算法-2008" class="headerlink" title="InfoMap算法-2008"></a>InfoMap算法-2008</h3><ul><li>Maps of random walks on complex networks reveal community structure</li><li>The map equation</li></ul><p>InfoMap与压缩编码、层次编码有直接联系，它初始论文题目为Maps of random walks on complex networks reveal community structure，在复杂网络上利用随机游走来揭示社区结构，并利用平均比特增益来决定如何合并社区。</p><p>首先需要提一下最小熵原理和最短编码长度，假设一共有$n$个不同的字符，每个字符出现的概率分别是$P=(p_1,p_2,\cdots,p_n)$，那么有两个问题我们可能会感兴趣？</p><ol><li>如何找到最优编码方案，使得总的平均编码长度最短？（Huffman编码）</li><li>理论上，这个平均编码长度是多少？（信息熵，如下）</li></ol><script type="math/tex; mode=display">\begin{aligned}H(P)=-\sum_{i=1}^n p_i\log_2 p_i\end{aligned}</script><p>编码的最短平均长度就是信息熵，也即无损压缩能力的极限，通过寻找更佳的方案去逼近这个极限便是最小熵。</p><p>对层次编码，考虑需要记忆一个序列：苹果、梨、上海、广州、 深圳、12，45，89。那么，我们一般不会直接按顺序记忆，而是分类记忆：前两个是水果，中间三个是城市，后面三个是数字。我们先对类别进行编码，再对对象进行编码，然后每一类结束加上一个终止标记，如：</p><div class="table-container"><table><thead><tr><th>水果</th><th>苹果</th><th>梨</th><th>End</th><th>城市</th><th>上海</th><th>广州</th><th>深圳</th><th>End</th><th>数字</th><th>12</th><th>45</th><th>89</th><th>End</th></tr></thead><tbody><tr><td>000</td><td>001</td><td>010</td><td>000</td><td>001</td><td>001</td><td>010</td><td>011</td><td>000</td><td>010</td><td>001</td><td>010</td><td>011</td><td>000</td></tr></tbody></table></div><p>有了特定层次的编码方案，就可以计算该方案的平均编码长度了，定义：<script type="math/tex">p_{\alpha}</script>为对象<script type="math/tex">\alpha</script>出现的概率，<script type="math/tex">q_{i\curvearrowright}</script>为类别$i$出现的概率，同样也是类别$i$终止标记出现的概率，它们三个都是全局归一化的概率，即：</p><script type="math/tex; mode=display">\begin{equation} \underbrace{\sum_i q_{i\curvearrowright}}_{\text{类别的概率总和}} + \underbrace{\sum_{\alpha}p_{\alpha}}_{\text{编码对象的概率总和}} + \underbrace{\sum_i q_{i\curvearrowright}}_{\text{终止标记的概率总和}} = 1\end{equation}</script><p>由于类和类内对象使用两套不同的编码，所以需要分别计算两者的平均编码长度，其中，类的平均编码长度是：</p><script type="math/tex; mode=display">\begin{aligned}H(Q)=-\sum_{i}\frac{q_{i\curvearrowright}}{q_\curvearrowright}\log\frac{q_{i\curvearrowright}}{q_\curvearrowright}\end{aligned}</script><p>其中，<script type="math/tex">{q_\curvearrowright}=\sum_{i}q_{i\curvearrowright}</script>，这是因为类的编码时独立一套的，将类的概率在类间归一化后，代入熵的公式就得到类的理论上的最短平均编码长度了。同样的，对于每个类$i$的类内对象的最短平均编码长度是：</p><script type="math/tex; mode=display">\begin{aligned}H(P^i)=-\frac{q_{i\curvearrowright}}{p_{i\circlearrowright}}\log\frac{q_{i\curvearrowright}}{p_{i\circlearrowright}}-\sum_{\alpha \in i}\frac{p_{\alpha}}{p_{i\circlearrowright}}\log\frac{p_{\alpha}}{p_{i\circlearrowright}}\end{aligned}</script><p>其中，<script type="math/tex">p_{i\circlearrowright}=q_{i\curvearrowright}+\sum_{\alpha \in i}p_{\alpha}</script>，每个类内对象都用独自的一套编码，这里连同终止标记概率在类内归一化后，代入熵的公式。最后，二者加权平均可以得到总的最短平均编码长度：</p><script type="math/tex; mode=display">\begin{aligned}L(M)={q_\curvearrowright}H(Q)+\sum_{i}p_{i\circlearrowright}H(P^i)\end{aligned}</script><p>这样，对于每一个序列，就需要我们去找到一个层次编码方案，是上式越小越好。</p><p>但是，经典的聚类问题并没有这种序列，InfoMap的想法是将聚类的节点网络看做一个有向图，任意两个节点$(\alpha,\beta)$都有一条$\beta \rightarrow \alpha$的边，边的权重为转移概率$p_{\beta} \rightarrow \alpha$。一般来说，节点之间的边也代表着两个点之间的相似度，然后我们可以通过将边的权重归一化来赋予它转移概率的含义。有了这个设定之后，一个很经典的想法——“随机游走”——就出来了：从某个点$j$开始，依概率$p(i|j)$跳转下一个点$i$，然后从$i$点出发，再依转移概率跳转到下一个点，重复这个过程。这样我们就可以得到一个很长的序列。有了序列之后，就能以找到最小的最短平均编码长度为目标来聚类了。</p><p>其实，我们不需要进行随机游走模拟，因为事实上我们不需要生成的序列，我们只需要知道随机游走生成的序列里边每个对象的概率，为此，我们只需要去解方程：</p><script type="math/tex; mode=display">\begin{equation}\begin{pmatrix}p_1\\p_2\\ \vdots \\p_n\end{pmatrix} = \begin{pmatrix}p_{1\to 1} & p_{2\to 1} & \cdots & p_{n\to 1}\\p_{1\to 2} & p_{2\to 2} & \cdots & p_{n\to 2} \\ \vdots& \vdots& \ddots & \vdots \\p_{1\to n} & p_{2\to n} & \cdots & p_{n\to n}\end{pmatrix} \begin{pmatrix}p_1\\p_2\\ \vdots \\p_n\end{pmatrix}\end{equation}</script><p>或者写成<script type="math/tex">p_{\beta}=\sum_{\alpha}p_\alpha p_{\alpha \rightarrow \beta}</script>，上式得到的是节点概率最终的平稳分布<script type="math/tex">(p_1,p_2,...,p_n)</script>，但是，单纯的随机游走可能会依赖迭代的初始值，上式的解可能不唯一，比如，有一些孤立的区域，进去便永远出不来了，那么区域外的节点的概率便全为0了。为了解决这个问题，作者引入了”穿越概率“$\tau$：以$1-\tau$的概率按照<script type="math/tex">p_{\beta \rightarrow \alpha}</script>的概率来随机游走，以$\tau$的概率随机选择网络中任意一个节点跳转，那么，节点$p_{\beta}$的概率为：</p><script type="math/tex; mode=display">p_{\beta}=(1-\tau)\sum_{\alpha}p_\alpha p_{\alpha \rightarrow \beta}+\tau\sum_{\alpha}p_\alpha \frac{1}{n}</script><p>相当于把转移概率<script type="math/tex">p_{\alpha \rightarrow \beta}</script>换成了<script type="math/tex">(1-\tau)p_{\alpha \rightarrow \beta}+{\tau}/{n}</script>，$\tau$作为一个超参数，作者取了$\tau=0.15$。</p><p>有了<script type="math/tex">p_\alpha</script>，还需要求<script type="math/tex">q_{i\curvearrowright}</script>，即类别的概率，也是终止标记的概率，出现终止标记意味着后面的类是已经不是第$i$类了，所以终止标记的概率实际上就是“从一个类别跳转到另一个类别的概率”，换言之就是随机游走过程中“离开$i$类”这件事情发生的概率，它等于：</p><script type="math/tex; mode=display">\begin{equation}q_{i\curvearrowright} = \sum_{\alpha\in i}\sum_{\beta\not\in i} p_{\alpha} p_{\alpha\to\beta}\end{equation}</script><p>若带有穿越概率的话，要将<script type="math/tex">p_{\alpha \rightarrow \beta}</script>换成<script type="math/tex">(1-\tau)p_{\alpha \rightarrow \beta}+{\tau}/{n}</script>，即为：</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}q_{i\curvearrowright} =& \sum_{\alpha\in i}\sum_{\beta\not\in i} p_{\alpha} \left[(1-\tau)p_{\alpha\to\beta} + \frac{\tau}{n}\right]\\ =& \tau\frac{n - n_i}{n}\sum_{\alpha\in i}p_{\alpha} + (1-\tau)\sum_{\alpha\in i}\sum_{\beta\not\in i} p_{\alpha}p_{\alpha\to\beta} \end{aligned}\end{equation}</script><p>其中，<script type="math/tex">n_i</script>是类<script type="math/tex">i</script>的类内对象数目。现在有了<script type="math/tex">p_\alpha</script>和<script type="math/tex">q_{i\curvearrowright}</script>的形式都出来了，只需要将二者归一化，然后找到最小的总的最短平均编码长度即可。</p><p>InfoMap的整个流程如下：</p><ol><li>定义好节点间的转移概率<script type="math/tex">p_{\alpha \rightarrow \beta}</script>；</li><li>数值求解得到$p_\alpha$；</li><li>搜索聚类方案，使得总的最短平均编码长度尽可能小。</li></ol><p>对于第3步，改进版的InfoMap中，算法大致如下：</p><ol><li>每个节点都初始化一个独立的类；</li><li>按照随机的顺序遍历每个节点，将每个节点都归到让总的平均编码长度下降幅度最大的那个相邻的类；</li><li>重复步骤2，每次都用不同的随机顺序，直到不再下降；</li><li>通过其他一些新的策略来精调前三步得到的聚类结果。</li></ol><p>可以发现，InfoMap就是建立在转移概率基础上的一种聚类/社区发现算法，有清晰的信息论解释（最小熵解释），并且几乎没有任何超参（或者说超参就是转移概率的构建）。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/itplus/article/details/41348651" target="_blank" rel="noopener">什么是社区发现?</a></p><p><a href="https://zhuanlan.zhihu.com/p/141401358" target="_blank" rel="noopener">社区发现算法综述—part1</a></p><p><a href="https://www.cnblogs.com/fengfenggirl/p/louvain.html" target="_blank" rel="noopener">模块度与Louvain社区发现算法</a></p><p><a href="http://www.yalewoo.com/modularity_community_detection.html" target="_blank" rel="noopener">Modularity的计算方法——社团检测中模块度计算公式详解</a></p><p><a href="https://www.cnblogs.com/LittleHann/p/10699988.html" target="_blank" rel="noopener">标签传播算法（Label Propagation Algorithm, LPA）初探</a></p><p><a href="https://greatpowerlaw.wordpress.com/2013/02/08/community-detection-lpa/" target="_blank" rel="noopener">Community Detection – Label Propagation算法</a></p><p><a href="https://kexue.fm/archives/7006" target="_blank" rel="noopener">最小熵原理（五）：“层层递进”之社区发现与聚类</a></p><p><a href="https://arxiv.org/abs/cond-mat/0112110v1" target="_blank" rel="noopener">论文：GN-算法</a></p><p><a href="https://arxiv.org/pdf/cond-mat/0309508v1.pdf" target="_blank" rel="noopener">论文：FN-算法</a></p><p><a href="https://arxiv.org/abs/0803.0476v2" target="_blank" rel="noopener">论文：Louvain算法</a></p><p><a href="https://arxiv.org/pdf/0709.2938.pdf" target="_blank" rel="noopener">论文：标签传播算法</a></p><p><a href="https://arxiv.org/pdf/0707.0609v3.pdf" target="_blank" rel="noopener">论文：InfoMap 初始论文</a></p><p><a href="https://arxiv.org/pdf/0906.1405v2.pdf" target="_blank" rel="noopener">论文：InfoMap 改进论文</a></p>]]></content>
      
      
      <categories>
          
          <category> 社区发现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 社区发现 </tag>
            
            <tag> 聚类 </tag>
            
            <tag> 社交网络 </tag>
            
            <tag> 统计推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>社区发现方法调研-深度学习</title>
      <link href="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>这次调研主要是从参考了发表在IJCAI 2020上一篇综述《Deep Learning for Community Detection: Progress, Challenges and Opportunities》，作者以三种广泛的深度学习方法回顾了社区检测领域中模型和算法开发的技术趋势以及当前的发展状况，并确定了需要通过深度学习来克服社区发现的七个挑战。</p><a id="more"></a><ul><li><p>Deep Learning for Community Detection: Progress, Challenges and Opportunities</p></li><li><p>IJCAI2020</p></li><li><p>该综述调研的文章主要来自：NIPS, ICLR, AAAI, IJCAI, KDD, ICDM, CIKM, ICDE和WWW，也包括一些高质量的同行评审期刊(peer-reviewed journals)。</p><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/title.png" alt="文章标题"></p></li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>网络/图的两个基本元素是节点和边。从连通性和密度的角度来看，社区被称为局部密集的连通子图或节点簇（clusters of nodes）。除了子图的内部衔接之外，还应考虑它们之间的分隔。为此，图论提出了两个特定的规则来划分社区：</p><ul><li>社区中的节点紧密连接；</li><li>不同社区中的节点稀疏连接。</li></ul><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/An example of community detection in a social network.png" alt="社交网络的社区划分"></p><p>网络中同一个社区内部的节点具有相似的观点、功能(function)或者意识(purpose)，可以帮助我们了解网络固有的模式和功能。例如，蛋白质互作用（PPI）网络中的社区检测用于发现具有相似生物学功能的蛋白质；在引文网络（citation networks）中，社区检测确定了各个研究主题的重要性、相互联系及其发展；在企业网络中，可以通过研究公司员工的线上社交关系以及线下内部资源管理对其进行分组；在Twitter和Facebook等社交网络中，具有共同兴趣或共同朋友的用户可能是同一社区的成员。</p><p>大多数传统的社区检测方法都基于统计推断和常见的机器学习的方法等。在传统的机器学习中，社区检测通常被认为是图上的聚类问题。但是这些方法高度依赖于数据的特征，例如，使用节点特征向量将节点划分为社区的谱聚类（2002）。随机块模型（2011）是检测社区并描述社区形成方式的最广泛使用的方法之一，但它不能解决当今复杂的数据集和复杂的社交场景下所带来的一些列问题。因此，网络规模和数据维度的扩大需要更强大的技术来以可行的计算速度保证其高效的性能。</p><ul><li>2011 Phys. Rev. E - Stochastic blockmodels and community structure in networks.</li></ul><p>至少就目前而言，深度学习是一种解决方案。通过深度学习，计算模型可以在多个抽象级别上学习数据的表示形式，这非常适合于网络数据。不仅其学习非线性特征的能力得到了极大的提高，而且可以降低数据的维度，从而扩大了网络分析任务的范围（如社区检测，节点分类和链接预测等）。</p><p>这篇文章从模型的角度对社区检测方法进行分类，可分为：基于深度神经网络（Deep Neural Networks）的方法，基于深度图嵌入（Deep Graph Embedding）的方法和基于图神经网络（Graph Neural Networks）的方法，最后介绍了当前尚未解决的挑战和未来研究方向。</p><h2 id="相关定义"><a href="#相关定义" class="headerlink" title="相关定义"></a>相关定义</h2><p><strong>定义1（网络）</strong>根据图论，加权网络表示为<script type="math/tex">G=(V,E,W)</script>，未加权网络表示为$G=(V,E)$，其中$V$和$E$表示节点和边的集合，$W$分别表示$E$相应的权重，以连接的强度或容量为单位。在未加权的网络中，$W$被视为1。子图$g \subseteq G$是保留原始网络结构的图划分。子图的划分遵循预定义（pre-define）的规则，不同的规则可能会导致不同形式的子图。社区是代表真实社会现象的一种子图。换句话说，社区是一组具有共同特征的人或对象。</p><p><strong>定义2（社区）</strong>社区是网络中节点密集连接的子图，稀疏连接的节点沟通了不同的社区。在这里，使用$C=\lbrace C_1,C_2,\cdots,C_k\rbrace$表示将网络$G$划分为$k$个社区的集合，其中$C_i$是社区划分的第$i$个社区。节点$v$属于社区$C_i$满足如下条件：社区内部每个节点的内部度大于其外部度。</p><p>因此，社区检测的目标是发现网络$G$中的社区$C$。</p><h2 id="为什么要用深度学习做社区检测？"><a href="#为什么要用深度学习做社区检测？" class="headerlink" title="为什么要用深度学习做社区检测？"></a>为什么要用深度学习做社区检测？</h2><p>与其他机器学习方法相比，深度学习在社区检测方面的明显优势是它能够对高维数据的特征表示进行编码。深度学习模型还可以学习节点、邻域和子图的模式。另外，它们对于与大型图数据的稀疏性更具弹性（resilient）。在许多现实世界中，大多数节点都是未标记的，并且数据中的社区几乎没有先验知识，因此深度学习是无监督学习任务的最佳选择。</p><p>除了简单地利用网络拓扑来检测社区之外，一些策略还探索语义描述作为节点特征。传统的社区检测方法主要基于邻接矩阵和节点属性矩阵[ Yang et al., 2013; He et al., 2017 ]。</p><ul><li>2013 ICDM - Community detection in networks with node attributes.</li><li>2017 AAAI - Joint identiﬁcation of network communities and semantics via integrative modeling of network topologies and node contents</li></ul><p>但深度学习可以创建更强大的节点属性表示和社区结构表示。为此，最近的研究表明，在深度学习社区检测中有希望的新方向–例如，基于深度非负矩阵分解（NMF）的方法和根据社区属性修改了深度学习模型等。</p><ul><li>2018 CIKM - Deep autoencoderlike nonnegative matrix factorization for community detection</li><li>2019 Future Gener. Comput. Syst - A distributed overlapping community detection model for large graphs using autoencoder.</li><li>2019 NIPS - vGraph: A generative model for joint community detection and node representation learning</li></ul><p>深度学习可能给社区发现未来带来的可能影响包括以下四点：</p><ul><li><p>性能提升；</p></li><li><p>在更多更丰富的特征上进行社区检测的能力；</p></li><li>以网络拓扑和节点属性为基础进行检测的能力，从而建立了更鲁棒并且性能更好的模型；</li><li>检测大规模网络中更复杂结构的能力。</li></ul><h2 id="基于深度学习的社区检测"><a href="#基于深度学习的社区检测" class="headerlink" title="基于深度学习的社区检测"></a>基于深度学习的社区检测</h2><ul><li>左边是社区检测面临的七大挑战：社区数量未知、层次网络、网络异构性、边上符号信息、社区嵌入、动态网络和大规模网络；</li><li>右边是基于深度学习的社区检测方法分类，可分为三大类：基于DNN的方法，基于深度图嵌入（Deep Graph Embedding）的方法和基于GNN的方法。</li></ul><p><img src="/2020/10/15/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E6%96%B9%E6%B3%95%E8%B0%83%E7%A0%94-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/challenge and approaches.png" alt="基于深度学习的社区检测方法的挑战与分类"></p><h3 id="基于DNN的社区检测"><a href="#基于DNN的社区检测" class="headerlink" title="基于DNN的社区检测"></a>基于DNN的社区检测</h3><p>在社区检测中，基于DNN的三种常用模型是卷积神经网络（CNNs）、自编码器和生成对抗网络（GANs）。</p><h4 id="基于CNN的方法"><a href="#基于CNN的方法" class="headerlink" title="基于CNN的方法"></a>基于CNN的方法</h4><p>CNNs的两个关键组成部分是卷积操作和卷积层上的池化操作：卷积运算使用卷积内核来减少计算成本；池化操作随后应用于特征映射，以确保CNNs的鲁棒性。</p><p>利用CNNs的优势，[2017]设计了一种新颖的CNN模型，以检测拓扑不完整网络（topologically incomplete networks）中的社区，不完整是指从现实世界网络中观测时会丢失一些边。 [2019]在CNN框架中增加稀疏矩阵卷积，来特定地处理与邻接矩阵相关的高维稀疏表示。</p><ul><li>2017 Physica A - Deep community detection in topologically incomplete networks.</li><li>2019 SAC - A deep learning based community detection approach. </li></ul><h4 id="基于自编码器的方法"><a href="#基于自编码器的方法" class="headerlink" title="基于自编码器的方法"></a>基于自编码器的方法</h4><p>堆叠自编码器(Stacked auto-encoders)是用于社区检测的一种非常强大的DNN模型。将自编码器应用于社区检测的灵感来自以下发现：自编码器和谱聚类在谱矩阵的低维近似方面具有相似的框架（frameworks）[Cao et al .2018b]。对于网络拓扑方面，[Bhatia and Rani. 2018]设计一种方法通过基于随机游走的个性化PageRank来学习节点社区，并通过优化社区结构的模块度进行微调。为了利用节点属性信息，[Cao et al. 2018b]提出了一种堆叠式自编码器，该编码器通过组合网络拓扑和节点属性进行社区检测，来增强DNN中隐藏层的泛化能力；为了进一步解决网络拓扑和节点属性之间的匹配问题，[Cao et al.2018a]通过引入自适应参数作为匹配项的折衷控制(trade-off control)，提出了一种图正则化自编码器方法。</p><ul><li>2018b Neurocomputing - Incorporating network structure with node contents for community detection on large networks using deep learning</li><li>2018 Knowl. Inf. Syst - DFuzzy: A deep learning-based fuzzy clustering model for large graphs.</li><li>2018a KSEM - Autoencoder based community detection with adaptive integration of network topology and node contents.</li></ul><p>为避免需要预先设置社区的数量，分层堆叠的自编码器可以根据网络结构有效地找到社区的中心[Bhatia and Rani. 2018]。此外，这种自选择机制可确保模型严格按照社区标准划分节点。自从提出以来，越来越多的方法开始自适应地学习社区结构，而不是预先定义一个数目。例如，[Choong et al. 2018]引入了混合高斯模型，以从社区结构中捕获高阶模式（higher-order patterns），并对观察到的网络的生成过程进行建模，来检测社区。</p><ul><li>2018 Knowl. Inf. Syst - DFuzzy: A deep learning-based fuzzy clustering model for large graphs.</li><li>2018 ICDM - Learning community structure with variational autoencoder.</li></ul><p>对于具有正负符号连接的网络，它们被称为有符号网络。为了处理边上的符号信息，半监督堆叠自编码器通过重构邻接矩阵来表示有符号网络，以进一步学习网络嵌入[Shen and Chung，2018]。</p><ul><li>2018 IEEE Trans. Cybern. - Deep network embedding for graph representation learning in signed networks.</li></ul><h4 id="基于生成对抗网络（GAN）的方法"><a href="#基于生成对抗网络（GAN）的方法" class="headerlink" title="基于生成对抗网络（GAN）的方法"></a>基于生成对抗网络（GAN）的方法</h4><p>GANs涉及两个相互竞争的深度神经网络，从而可以快速调整训练精度。这些方法通常在无监督的情况下运行，从而生成具有与训练集相同统计特征的新数据，[Wang等，2019]探索了利用GAN来进行高效的图表示学习任务。</p><ul><li>2019 IEEE Trans. Knowl. Data. - Learning graph representation with generative adversarial nets. </li></ul><p>[Jia et al. 2019]认为基于图聚类的传统社区检测方法无法处理社区的密集重叠（dense overlapping），因为一个节点可能属于多个社区。为此，他们提出了一种新颖的CommunityGAN模型，该模型解决了重叠社区检测和基于GANs的图表示学习；更重要的是，与没有特定含义的图节点表示相比，CommunityGAN具有表示节点对社区的隶属强度的能力。</p><ul><li>2019 WWW - CommunityGAN: Community detection with generative adversarial nets.(*)</li></ul><h3 id="基于深度图嵌入的社区检测"><a href="#基于深度图嵌入的社区检测" class="headerlink" title="基于深度图嵌入的社区检测"></a>基于深度图嵌入的社区检测</h3><p>深度图嵌入是将网络中的节点映射到低维空间的一种技术，同时在表示中保留尽可能多的结构信息。图嵌入方法特别适合基于网络分析的机器学习任务，例如，链接预测、节点分类和节点聚类等，因为他们可以直接利用表示中的隐特征而不是去搜索网络。之后，可以利用聚类方法（例如k均值）进行社区检测。</p><h4 id="基于深度非负矩阵分解（NMF）的方法"><a href="#基于深度非负矩阵分解（NMF）的方法" class="headerlink" title="基于深度非负矩阵分解（NMF）的方法"></a>基于深度非负矩阵分解（NMF）的方法</h4><p>非负矩阵分解（NMF）可将一个矩阵分解为两个矩阵，并且这三个矩阵都没有负元素。对于社区检测，通过进一步最小化聚类任务的误差函数，将网络的邻接矩阵近似地分解为两个非负矩阵的乘积。[Ye et al, 2018]提出了一种新颖的深度NMF模型，该模型通过在深度学习过程中，将社区结构映射到原始网络结构来提升性能，并通过添加节点属性形成属性图，基于深度NMF的社区检测仅仅需要将邻接矩阵和节点属性矩阵进行分解。此外，[Li et al, 2018]根据深度特征学习和深度网络嵌入，使用NFM进行基于节点属性和社区嵌入的属性社区检测（attributed community detection）。</p><ul><li>2018 CIKM - Deep autoencoderlike nonnegative matrix factorization for community detection.(*)</li><li>2018 AAAI - Community detection in attributed graphs: an embedding approach.(*)</li></ul><h4 id="基于深度稀疏滤波（SF）的方法"><a href="#基于深度稀疏滤波（SF）的方法" class="headerlink" title="基于深度稀疏滤波（SF）的方法"></a>基于深度稀疏滤波（SF）的方法</h4><p>嵌入可以对成对关系的输入进行编码以避免搜索稀疏的邻接矩阵，因此，稀疏滤波（SF）是一种有效的深度特征学习（deep feature learning）算法，只需要一个超参数即可处理高维输入[Ngiam. 2011]。 [Xie et al. 2018]提出了一种有效的网络表示方法，该方法通过深度稀疏滤波的方式在网络社区发现中发挥作用，该方法尤其适用于大型网络。一种无监督的深度学习算法提取网络特征，然后用于社区划分。</p><ul><li>2011 NIPS - Sparse ﬁltering</li><li>2018 Pattern Recognit - Community discovery in networks with deep sparse ﬁltering</li></ul><h4 id="基于社区嵌入的方法"><a href="#基于社区嵌入的方法" class="headerlink" title="基于社区嵌入的方法"></a>基于社区嵌入的方法</h4><p>传统上，图嵌入专注于单个节点，但是网络中的社区反映了高阶相似性（high-order proximities），例如相似的观点和行为。这是图嵌入的一个重要但尚未充分研究的领域，重点是社区嵌入，其目标是了解低维空间中社区的节点分布。 [Cavallari et al，2017]调查了这一想法，认为这种新颖且简单（non-trivial）的策略可能有益于社区发现。例如，通过一种过渡（transitional）图嵌入的方法，可以使用节点分布来保留网络结构，从而反向改善社区检测。 [Zhang et al，2018]提出了一种保留社区的网络嵌入方法来学习网络表示。此外，[Tu et al，2019]提出了一种新的图嵌入模型，该模型可以学习节点和社区的嵌入，在优化过程中二者是交替进行，而非同时解决这两个任务。</p><ul><li>2017 CIKM - Learning community embedding with community detection and node embedding on graphs.(*)</li><li>2018 AAAI - Cosine: Community-preserving social network embedding from information diffusion cascades.(*)</li><li>2019 IEEE Trans. Knowl. Data Eng. - A uniﬁed framework for community detection and network representation learning.(*)</li></ul><h3 id="基于GNN的社区检测"><a href="#基于GNN的社区检测" class="headerlink" title="基于GNN的社区检测"></a>基于GNN的社区检测</h3><p>GNNs是图挖掘和深度学习的技术融合，它们的快速发展证明了它们在建模和捕获图数据中复杂关系的能力。例如，[Chen et al，2019]中用于监督社区检测的GNN引入了一个非回溯算子（a non-backtracking operator）来定义边邻接性(edge adjacency)，它不仅是提高学习性能的可行性方法，而且算子选择也很方便。</p><p>图卷积网络（GCNs）继承了CNNs快速学习的特点，并通过集成了考虑网络中实体概率分布的概率模型，进一步改善了这个优点。例如，[Jin et al. 2019]将马尔可夫随机场与语义信息属性网络相结合以支持半监督学习，而[Shchur and Gunnemann，2019]集成了伯努利-泊松（Bernoulli-Poisson）概率模型与GCN来实现重叠社区检测，使得卷积层可以识别复杂的网络模式。</p><ul><li>2019 ICLR - Supervised community detection with line graph neural networks.</li><li>2019 AAAI - Graph convolutional networks meet markov random ﬁelds: Semisupervised community detection in attribute networks.</li><li>2019 KDD Workshop DLG’19 - Overlapping community detection with graph neural networks.</li></ul><h2 id="挑战和机遇"><a href="#挑战和机遇" class="headerlink" title="挑战和机遇"></a>挑战和机遇</h2><h3 id="社区数量未知"><a href="#社区数量未知" class="headerlink" title="社区数量未知"></a>社区数量未知</h3><p>到目前为止，网络中社区数量的未知性没有得到很好的解决。在现实世界中，提取的大多数数据都没有标签，因此，在机器学习中，社区检测通常被视为无监督的聚类问题。这导致了一个左右为难（catch-22）问题：需要对数据进行标记以确定社区的数量，但是在对数据进行标记之前需要知道社区的数量。深度学习方法通过根据一个或多个隐空间中的相似性对节点进行聚类，在某种程度上解决此问题。但是，聚类算法仍然需要提前知道最终的聚类数。</p><p>机会(Opportunities:)：到目前为止，一种有效的解决方案是通过分析网络拓扑来计算社区数量，例如[Bhatia and Rani，2018; Bhatia and Rani，2019年]基于随机游走的个性化PageRank。但是，这类方法不能保证将网络中的每个节点都分配给一个社区。因此，尚未找到针对该问题完整的解决方案。</p><ul><li>2018 Knowl. Inf. Syst. - DFuzzy: A deep learning-based fuzzy clustering model for large graphs.</li><li>2019 Future Gener. Comput. Syst. - A distributed overlapping community detection model for large graphs using autoencoder.</li></ul><h3 id="层次网络（Hierarchical-Networks）"><a href="#层次网络（Hierarchical-Networks）" class="headerlink" title="层次网络（Hierarchical Networks）"></a>层次网络（Hierarchical Networks）</h3><p>层次网络由分层网络组成，其中每层网络共享特定的功能（functions）。因此，社区检测策略必须能够提取分层表示（layer-wise representations）。挑战包括：区分不同的关系类型（例如水平和垂直），以及管理（manage）不同层中不同级别（levels）的稀疏性。</p><p>机会：[Song和Thiagarajan，2018年]提出了一种多层DeepWalk，通过创建层间的边（inter-layer edges）以利用跨不同层（across different layers）的依赖性，同时保留层次结构；它学习每层中每个节点的表示，并将这些表示通过优化策略进行微调。另一个可能的解决方案是同时优化适用于所有层的公共表示和保留特定层网络结构的局部表示。此外，上述方案对于层次网络中层数的可伸缩性令人怀疑，在设计新的解决方案时应予以考虑。另外，需要新的模型来区分层次网络中不同类型的连接（links）。因此，在我们利用深度学习方法来检测层次网络的社区之前，还有大量工作要做。</p><ul><li>2019 IEEE Big Data - Improved deep embeddings for inferencing with multi-layered networks.</li></ul><h3 id="网络异构性（Network-Heterogeneity）"><a href="#网络异构性（Network-Heterogeneity）" class="headerlink" title="网络异构性（Network Heterogeneity）"></a>网络异构性（Network Heterogeneity）</h3><p>网络异质性是指包含明显不同类型的节点和边的网络，这意味着用于同构网络的策略不一定有效。特别地，在模型和算法的设计中需要解决与每种类型的节点相关的不同概率分布。</p><p>机会：迄今为止，很少有深度学习方法考虑网络异构性。[Chang et al，2015]通过非线性嵌入函数来捕获异构网络中节点之间的复杂交互，从而解决了这个问题；然而，他们的方法忽略了节点之间关系的不同语义。异构网络中社区检测的机会可能包括：</p><ol><li>深度图嵌入模型和支持算法（supporting algorithms）；</li><li>具有新颖训练过程的特定深度学习模型，以学习隐藏层中的异构图属性（heterogeneous graph properties）； </li><li>可以利用节点之间不同类型边的新模型。</li></ol><ul><li>2015 KDD - Heterogeneous network embedding via deep architectures.</li></ul><h3 id="边上符号信息（Signed-Information-on-Edges）"><a href="#边上符号信息（Signed-Information-on-Edges）" class="headerlink" title="边上符号信息（Signed Information on Edges）"></a>边上符号信息（Signed Information on Edges）</h3><p>现实世界中许多网络都有代表正负符号的边，该问题的挑战在于如何以不同的方式区别对待这样的边。</p><p>机会：一种可行的解决方案是通过设计随机行走过程来合并（incorporate）正边和负边。 [Hu et al，2019]按照这个想法，设计了一个基于词嵌入的稀疏图嵌入模型，但是对于现实世界中某些小型的带符号网络，其方法的性能不如基准(baseline)的谱方法；另一种可能解决方案是重建有符号网络的邻接矩阵表示，但是，这带来了其他问题，因为在现实世界中，邻接关系绝大多数都是正边。 [Shen and Chung，2018]通过增加了惩罚项，来确保其堆叠的自编码器模型更多地关注在大量的正边上重建稀疏的负边，但是，如果没有对社区中大多数关系的先验知识（这在许多情况下是现实的），该方法将行不通。因此，目前仍然需要在符号网络中进行无监督社区检测的有效方法。</p><ul><li>2019 J. Ambient Intell. Hum. Comput. - Sparse network embedding for community detection and sign prediction in signed social networks</li><li>2018 IEEE Trans. Cybern. - Deep network embedding for graph representation learning in signed networks.</li></ul><h3 id="社区嵌入"><a href="#社区嵌入" class="headerlink" title="社区嵌入"></a>社区嵌入</h3><p>社区嵌入的目的是创建社区的表示形式，而不是每个节点的表示形式。因此，焦点转移到了社区感知的高阶邻近度（high-order proximity），而不是与节点邻域相关的1阶或2阶邻近度。这是一个新兴的研究领域，需要克服三个主要挑战：</p><ol><li>高计算成本；</li><li>节点与社区结构之间的关系评估；</li><li>应用深度学习模型时的其他问题，例如跨社区的分布转移。</li></ol><p>机会：文中提出以下研究目标：</p><ol><li>探索如何将社区嵌入整合到深度学习模型中；</li><li>确定如何直接嵌入社区结构以获得一系列好处，例如快速计算； </li><li>在集成了深度社区检测学习的模型中，设一种计优化超参数的方法。</li></ol><h3 id="动态网络"><a href="#动态网络" class="headerlink" title="动态网络"></a>动态网络</h3><p>动态变化会影响网络拓扑或节点属性，每个属性都必须以自己的方式进行处理。拓扑更改（例如添加或删除节点或边）不仅会导致局部社区发生更改，而且还会导致整个网络的社区划分发生改变[Liu et al. 2020]。使用动态网络，需要通过一系列网络快照来重新训练深度学习模型。动态网络的时间属性（temporal attributes）所面临的技术挑战在于动态的深度特征提取。</p><ul><li>2020 WWW - Detecting the evolving community structure in dynamic social networks</li></ul><p>机会：动态网络中用于检测具有动态时空特性社区的深度学习方法还未被很好地设计出来，因此，未来的研究方向包括：</p><ol><li>检测并识别社区的空间变化（spatial changes）；</li><li>学习嵌入时间特征（temporal feature ）和社区结构信息（community structure information）的深层模式（deep patterns）；</li><li>设计一种统一深度学习方法用于社区检测，且该方法可以同时处理空间和时间特征。</li></ol><h3 id="大规模网络"><a href="#大规模网络" class="headerlink" title="大规模网络"></a>大规模网络</h3><p>当先现实世界中，大型网络可以包含数百万节点、边和结构模式（structural patterns），并且还会高度动态化，如类似Facebook和Twitter的社交网络。在大规模网络中社区发现实现之前，有许多需要解决的问题。例如，大型网络可能具有其固有的规模特征，例如社交网络中的无规模（即幂律度分布，比如完全图度分布，d=n-1的概率是1，d=0的概率是0；随机网络度分布满足正态分布；无尺度网络：大部分的节点只有比较少的连接，而少数节点有大量的连接，不存在特征度数，故称无尺度）。这种分布会影响深度学习在社区检测中的性能，可扩展性也是使深度学习能够检测大型网络中社区的另一个关键问题，而且不断变化的网络类型进一步增加了检测难度。总体而言，大规模网络中的深度社区检测涉及上述所有六个挑战以及可扩展学习的挑战。</p><p>机会：要在大规模网络中充分利用丰富的信息，就需要新的无监督聚类算法，该算法要具有较低的计算复杂度和更大的灵活性。分布式计算在大规模机器学习中很流行。因此，一个可能的方向是设计一种鲁棒的深度学习社区检测方法，且需要实现高性能的协同计算。另一方面，关于高维邻接矩阵，深度学习中常用的降维关键策略（即矩阵低秩逼近）不适用于大规模网络，即使是目前的分布式计算解决方案也是相当耗费计算资源。因此，大规模网络中社区划分中迫切需要新的深度学习框架、模型和算法。作为社区检测中最大的挑战，这些框架在准确性和速度上需要远远超过当前的基准（benchmarks）。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>传统的社区检测方法通常依赖于统计推断和常规的机器学习方法，深度学习的进步推动了社区检测策略发展，该策略具有更强大的能力来处理高维图数据。在这篇综述中，作者以三种广泛的深度学习方法回顾了社区检测领域中模型和算法开发的技术趋势以及当前的发展状况，并确定了需要通过深度学习来克服社区发现的七个挑战。</p>]]></content>
      
      
      <categories>
          
          <category> 社区发现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 社区发现 </tag>
            
            <tag> 社区检测 </tag>
            
            <tag> 图神经网络 </tag>
            
            <tag> 图嵌入 </tag>
            
            <tag> 聚类 </tag>
            
            <tag> 社交网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中调用C语言代码</title>
      <link href="/2019/10/11/Python%E4%B8%AD%E8%B0%83%E7%94%A8C%E8%AF%AD%E8%A8%80%E4%BB%A3%E7%A0%81/"/>
      <url>/2019/10/11/Python%E4%B8%AD%E8%B0%83%E7%94%A8C%E8%AF%AD%E8%A8%80%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<p>首先，我们要明确为什么要在Python中调用C？比较常见原因如下： </p><ul><li>你要提升代码的运行速度，而且你知道C要比Python快50倍以上。</li><li>C语言中有很多传统类库，而且有些正是你想要的，但你又不想用Python去重写它们</li><li>想对从内存到文件接口这样的底层资源进行访问。 </li><li>不需要理由，Just想玩玩。</li></ul><p>更详细请点击<a href="https://blog.csdn.net/qq_35636311/article/details/78255568" target="_blank" rel="noopener">这里</a>。</p><a id="more"></a><h1 id="使用C扩展"><a href="#使用C扩展" class="headerlink" title="使用C扩展"></a>使用C扩展</h1><p>开发者有三种方法可以在自己的Python代码中来调用C编写的函数，分别是<strong>ctypes</strong>、<strong>SWIG</strong>，<strong>Python/C API</strong>，但每种方式也都有各自的利弊。</p><h1 id="Ctype"><a href="#Ctype" class="headerlink" title="Ctype"></a>Ctype</h1><p>Python中的<strong><a href="https://docs.python.org/2/library/ctypes.html" target="_blank" rel="noopener">ctypes模块</a></strong>可能是Python调用C方法中最简单的一种。ctypes模块提供了和C语言兼容的数据类型和函数来加载dll文件，因此在调用时不需对源文件做任何的修改，故该方法很简单。下面用C编写一个两数求和的<code>add.c</code>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//sample C file to add 2 numbers - int and floats</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add_int</span><span class="params">(<span class="keyword">int</span>, <span class="keyword">int</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">add_float</span><span class="params">(<span class="keyword">float</span>, <span class="keyword">float</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add_int</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> num1 + num2;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">add_float</span><span class="params">(<span class="keyword">float</span> num1, <span class="keyword">float</span> num2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> num1 + num2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来将C文件编译为<code>.so</code>文件(Windows下为DLL)。下面操作会生成<code>adder.so</code>文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#For Linux</span></span><br><span class="line">$ gcc -shared -Wl,-soname,adder -o adder.so -fPIC add.c</span><br><span class="line"> </span><br><span class="line"><span class="comment">#For Mac</span></span><br><span class="line">$ gcc -shared -Wl,-install_name,adder.so -o adder.so -fPIC add.c</span><br></pre></td></tr></table></figure><p>然后在Python中调用即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line"><span class="comment">#load the shared object file</span></span><br><span class="line">adder = CDLL(<span class="string">'./adder.so'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Find sum of integers</span></span><br><span class="line">res_int = adder.add_int(<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Sum of 4 and 5 = "</span> + str(res_int))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Find sum of floats</span></span><br><span class="line">a = c_float(<span class="number">5.5</span>)</span><br><span class="line">b = c_float(<span class="number">4.1</span>)</span><br><span class="line"> </span><br><span class="line">add_float = adder.add_float</span><br><span class="line">add_float.restype = c_float</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Sum of 5.5 and 4.1 = "</span>, str(add_float(a, b)))</span><br></pre></td></tr></table></figure><p>在这个例子中，C文件是自解释的，它包含两个函数，分别实现了整形求和和浮点型求和。</p><p>在Python文件中，一开始先导入ctypes模块，然后<strong>使用CDLL函数来加载我们创建的库文件</strong>。这样我们就可以通过变量<code>adder</code>来使用C类库中的函数了。当<code>adder.add_int()</code>被调用时，内部将发起一个对C函数<code>add_int()</code>的调用。ctypes接口允许我们在调用C函数时使用原生Python中默认的字符串型和整型。</p><p>而对于其他类似布尔型和浮点型这样的类型，必须要使用正确的ctype类型才可以。如向<code>adder.add_float()</code>函数传参时, 我们要先将Python中的十进制值转化为<code>c_float</code>类型，然后才能传送给C函数。这种方法虽然简单，清晰，但是却很受限。例如，并不能在C中对对象进行操作。</p><h1 id="SWIG"><a href="#SWIG" class="headerlink" title="SWIG"></a>SWIG</h1><p>SWIG是Simplified Wrapper and Interface Generator的缩写，是Python中调用C代码的另一种方法。在这个方法中，开发人员必须编写一个额外的接口文件来作为SWIG(终端工具)的入口。</p><p><strong>Python开发者一般不会采用这种方法，因为大多数情况它会带来不必要的复杂。</strong>而当你有一个C/C++代码库需要被多种语言调用时，这将是个非常不错的选择。来自<a href="http://www.swig.org/tutorial.html" target="_blank" rel="noopener">SWIG官网</a>的示例如下，但未实验：</p><p><code>example.c</code>文件中的C代码包含了不同的变量和函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="keyword">double</span> My_variable = <span class="number">3.0</span>;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fact</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> n*fact(n<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">my_mod</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (x%y);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">get_time</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">time_t</span> ltime;</span><br><span class="line">    time(&amp;ltime);</span><br><span class="line">    <span class="keyword">return</span> ctime(&amp;ltime); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后编译它：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unix % swig -python example.i</span><br><span class="line">unix % gcc -c example.c example_wrap.c -I/usr/local/include/python2.1</span><br><span class="line">unix % ld -shared example.o example_wrap.o -o _example.so</span><br></pre></td></tr></table></figure><p>最后，Python输出如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import example</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; example.fact(5)</span></span><br><span class="line">120</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; example.my_mod(7,3)</span></span><br><span class="line">1</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; example.get_time()</span></span><br><span class="line">'Sun Feb 11 23:01:07 1996'</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></span><br></pre></td></tr></table></figure><p>可以看出，使用SWIG确实达到了同样的效果，虽然下了更多的工夫，但如果你的目标是多语言还是很值得的。</p><h1 id="Python-C-API"><a href="#Python-C-API" class="headerlink" title="Python/C API"></a>Python/C API</h1><p>Python/C API可能是被最广泛使用的方法。它不仅简单，而且可以在C代码中操作你的Python对象。这种方法需要以特定的方式来编写C代码以供Python去调用它。所有的Python对象都被表示为一种叫做PyObject的结构体，并且<code>Python.h</code>头文件中提供了各种操作它的函数。例如，如果PyObject表示为PyListType(列表类型)时，那么我们便可以使用<code>PyList_Size()</code>函数来获取该结构的长度，类似Python中的<code>len(list)</code>函数。大部分对Python原生对象的基础函数和操作在<code>Python.h</code>头文件中都能找到。接下来，编写一个C扩展，添加所有元素到一个Python列表(所有元素都是数字)，然后来看一下我们要实现的效果，这里示例了用Python调用C扩展的代码。</p><p>来看一下我们要实现的效果，这里演示了用Python调用C扩展的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Though it looks like an ordinary python import, the addList module is implemented in C</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> addList</span><br><span class="line"></span><br><span class="line">l = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Sum of List - "</span> + str(l) + <span class="string">" = "</span> +  str(addList.add(l)))</span><br></pre></td></tr></table></figure><p>上面的代码和普通的Python文件并没有什么分别，导入并使用了另一个叫做<code>addList</code>的Python模块。唯一差别就是这个模块并不是用Python编写的，而是C。</p><p>接下来我们看看如何用C编写addList模块，这可能看起来有点让人难以接受，但是一旦你了解了这之中的各种组成，你就可以一往无前了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Python.h has all the required function definitions to manipulate the Python objects</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Python.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//This is the function that is called from your python code</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> PyObject* <span class="title">addList_add</span><span class="params">(PyObject* self, PyObject* args)</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">    PyObject * listObj;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//The input arguments come as a tuple, we parse the args to get the various variables</span></span><br><span class="line">    <span class="comment">//In this case it's only one list variable, which will now be referenced by listObj</span></span><br><span class="line">    <span class="keyword">if</span> (! PyArg_ParseTuple( args, <span class="string">"O"</span>, &amp;listObj ))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//length of the list</span></span><br><span class="line">    <span class="keyword">long</span> length = PyList_Size(listObj);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//iterate over all the elements</span></span><br><span class="line">    <span class="keyword">int</span> i, sum =<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        <span class="comment">//get an element out of the list - the element is also a python objects</span></span><br><span class="line">        PyObject* temp = PyList_GetItem(listObj, i);</span><br><span class="line">        <span class="comment">//we know that object represents an integer - so convert it into C long</span></span><br><span class="line">        <span class="keyword">long</span> elem = PyInt_AsLong(temp);</span><br><span class="line">        sum += elem;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//value returned back to python code - another python object</span></span><br><span class="line">    <span class="comment">//build value here converts the C long to a python integer</span></span><br><span class="line">    <span class="keyword">return</span> Py_BuildValue(<span class="string">"i"</span>, sum);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//This is the docstring that corresponds to our 'add' function.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> addList_docs[] =</span><br><span class="line"><span class="string">"add(  ): add all elements of the list\n"</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* This table contains the relavent info mapping -</span></span><br><span class="line"><span class="comment">   &lt;function-name in python module&gt;, &lt;actual-function&gt;,</span></span><br><span class="line"><span class="comment">   &lt;type-of-args the function expects&gt;, &lt;docstring associated with the function&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> PyMethodDef addList_funcs[] = &#123;</span><br><span class="line">    &#123;<span class="string">"add"</span>, (PyCFunction)addList_add, METH_VARARGS, addList_docs&#125;,</span><br><span class="line">    &#123;<span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   addList is the module name, and this is the initialization block of the module.</span></span><br><span class="line"><span class="comment">   &lt;desired module name&gt;, &lt;the-info-table&gt;, &lt;module's-docstring&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">initaddList</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">    Py_InitModule3(<span class="string">"addList"</span>, addList_funcs,</span><br><span class="line">            <span class="string">"Add all ze lists"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><code>Python.h</code>头文件中包含了所有需要的类型(Python对象类型的表示)和函数定义(对Python对象的操作)；</li><li><p>接下来我们编写将要在Python调用的函数, 函数传统的命名方式由<code>{模块名}_{函数名}</code>组成，所以我们将其命名为<code>addList_add</code>；</p></li><li><p>然后填写想在模块内实现函数的相关信息表，每行一个函数，以空行作为结束 </p></li><li>最后的模块初始化块签名为<code>PyMODINIT_FUNC init{模块名}</code>。</li></ul><p>函数<code>addList_add()</code>接受的参数类型为PyObject类型结构(同时也表示为元组类型，因为Python中万物皆为对象，所以我们先用PyObject来定义)。传入的参数则通过<code>PyArg_ParseTuple()</code>来解析。第一个参数是被解析的参数变量。第二个参数是一个字符串，告诉我们如何去解析元组中每一个元素。字符串的第n个字母正是代表着元组中第n个参数的类型。例如，”i”代表整形，”s”代表字符串类型, “O”则代表一个Python对象。接下来的参数都是你想要通过<code>PyArg_ParseTuple()</code>函数解析并保存的元素。这样参数的数量和模块中函数期待得到的参数数量就可以保持一致，并保证了位置的完整性。例如，我们想传入一个字符串，一个整数和一个Python列表，可以这样去写:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="keyword">char</span> *s;</span><br><span class="line">PyObject* <span class="built_in">list</span>;</span><br><span class="line">PyArg_ParseTuple(args, <span class="string">"isO"</span>, &amp;n, &amp;s, &amp;<span class="built_in">list</span>);</span><br></pre></td></tr></table></figure><p>在这种情况下，我们只需要提取一个列表对象，并将它存储在listObj变量中。然后用列表对象中的<code>PyList_Size()</code>函数来获取它的长度。就像Python中调用<code>len(list)</code>。现在我们通过循环列表，使用<code>PyList_GetItem(list, index)</code>函数来获取每个元素。这将返回一个<code>PyObject*</code>对象。既然Python对象也能表示PyIntType，我们只要使用<code>PyInt_AsLong(PyObj *)</code>函数便可获得我们所需要的值。我们对每个元素都这样处理，最后再得到它们的总和。总和将被转化为一个Python对象并通过<code>Py_BuildValue()</code>返回给Python代码，这里的i表示我们要返回一个Python整形对象。至此，我们已经编写完C模块了，将下列代码保存为<code>setup.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build the modules</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup, Extension</span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">'addList'</span>, version=<span class="string">'1.0'</span>, ext_modules=[Extension(<span class="string">'addList'</span>, [<span class="string">'adder.c'</span>])])</span><br></pre></td></tr></table></figure><p>并且运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py install</span><br></pre></td></tr></table></figure><p><strong>我用的是python3.6，在执行install时出现了错误，然后是python2.7执行成功</strong>。如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python2 setup.py install</span><br></pre></td></tr></table></figure><p>现在应该已经将我们的C文件编译安装到我们的Python模块中了。接下来，让我们来验证下我们的模块是否有效：</p><p>在一番辛苦后，让我们来验证下我们的模块是否有效</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># module that talks to the C code</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> addList</span><br><span class="line"></span><br><span class="line">l = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Sum of List - "</span> + str(l) + <span class="string">" = "</span> +  str(addList.add(l)))</span><br></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sum of List - [1, 2, 3, 4, 5] = 15</span><br></pre></td></tr></table></figure><p>如你所见，我们已经使用<code>Python.h</code>（API）成功开发出了我们第一个Python C扩展。这种方法看似复杂，但你一旦习惯，它将变的非常有效。Python调用C代码的另一种方式便是使用Cython让Python编译的更快。但是Cython和传统的Python比起来可以将它理解为另一种语言，所以我们就不在这里过多描述了。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统论文笔记</title>
      <link href="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文主要介绍一些自己阅读推荐统的论文笔记，会不定期更新，目前是排序学习的一些相关论文。</p><ul><li>排序是对一组物品列表按照某种方式进行排序，来最大化整个列表的效用的过程，广泛应用于搜索引擎、推荐系统、机器翻译、对话系统甚至计算生物学。一些监督机器学习技术经常被广泛应用在这些问题中，这些技术称作排序学习技术。<a id="more"></a></li></ul><h1 id="《DeepFM-A-Factorization-Machine-based-Neural-Network-for-CTR-Prediction》"><a href="#《DeepFM-A-Factorization-Machine-based-Neural-Network-for-CTR-Prediction》" class="headerlink" title="《DeepFM: A Factorization-Machine based Neural Network for CTR Prediction》"></a>《DeepFM: A Factorization-Machine based Neural Network for CTR Prediction》</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><a href="https://arxiv.org/pdf/1703.04247.pdf" target="_blank" rel="noopener">DeepFM</a>是2017年提出的一种端到端模型，它解决了Wide &amp; Deep Learning中<strong>手工设计特征</strong>的问题。DeepFM融合了Factorization Machine(FM)的推荐优势和Deep Learing的特征提取优势。其中FM部分能够建模特征间的低阶关联，Deep部分能够建模特征间的高阶关联。</p><p>DeepFM的主要优势如下：</p><ul><li>FM+DNN：FM部分实现低阶的特征提取，DNN实现高阶的特征提取。同时无需做特征工程。</li><li>训练高效：DeepFM的FM部分和Deep部分共享同一输入向量和嵌入向量。</li></ul><h2 id="DeepFM方法详解"><a href="#DeepFM方法详解" class="headerlink" title="DeepFM方法详解"></a>DeepFM方法详解</h2><p>假设数据集包含$n$个样本$(\mathbf{x},y)$，其中$y$是标签，取0和1；$\mathbf{x}$是由m个fields组成的数据，每条数据由$(u,i)$数据对组成，$u$和$i$分别指的是点播影院辅助信息和影片描述特征，它们可以包括类别字段（比如点播影院的省份、城市、影片的类型等），又可以包括连续值特征（比如影片评分等），其中类别型特征使用one-hot方式来表示，连续值特征先根据其分布离散化后，再使用one-hot方式表示。</p><h3 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h3><p>DeepFM包含两部分：FM部分与Deep部分，分别负责低阶特征的提取和高阶特征的提取。这两部分共享同样的输入。对于特征$i$，标量$w_i$ 用于表示其一阶权重。隐向量$\mathbf{v}_i$用以表示特征$i$与其他特征之间的相互作用。$\mathbf{v}_i$在FM部分是用以对2阶特征进行建模，即特征之间的相互作用；$\mathbf{v}_i$输入到Deep部分则是用以进行高阶特征建模。DeepFM的预测结果可以写为：</p><script type="math/tex; mode=display">\hat{y}=\sigma(y_{FM}(\mathbf{x})+y_{DNN}(\mathbf{x}))</script><p>DeepFM的框架如下：</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DeepFM%E7%9A%84%E6%A1%86%E6%9E%B6.png" class title="This is an image"><p>上图是，它将Wide&amp;Deep Learning中的Wide组件使用FM替换，并且两部分共享同一输入向量和嵌入向量。</p><p>其中最下面的稀疏特征层中，黄色圈和蓝色圈表示经过one-hot编码后原始稀疏特征(分别取值1和0)，可以看到每个field中的黄色圈都有一条直接指向FM层中的Addition黑色的线，这代表FM中的一阶项；由Dense Embeddings层中指向FM的红色线代表的是FM模型中二阶项的$w_{ij}=⟨\mathbf{v}_i,\mathbf{v}_j⟩$中的$\mathbf{v}_i$和$\mathbf{v}_j$；而指向Deep部分中的黑色的线是稀疏特征嵌入后的稠密特征。</p><p>另外，之所以说不需要人工特征工程，是因为交叉特征工作是模型自动进行的，在输入侧不需要手动进行交叉特征处理。</p><h3 id="FM部分"><a href="#FM部分" class="headerlink" title="FM部分"></a>FM部分</h3><p>FM部分是一个因子分解机。因为引入了隐变量的原因，对于几乎不出现或者很少出现的隐变量，FM也可以很好的学习。</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DeepFM%E4%B8%ADFM%E9%83%A8%E5%88%86.png" class title="This is an image"><p>FM的输出公式如下：</p><script type="math/tex; mode=display">y(\mathbf{x})=w_0+\sum_{i=1}^n(w_i\mathbf{x})+\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}<\mathbf{v}_i,\mathbf{v}_j>\mathbf{x}_i\mathbf{x}_j</script><h3 id="Deep部分"><a href="#Deep部分" class="headerlink" title="Deep部分"></a>Deep部分</h3><p>深度部分是一个前馈神经网络,用以获取高阶特征间相互作用。与图像或者语音这类连续而且密集的输入不同，它的的输入一般是极其稀疏，超高维，离散型和连续型混合且多字段的。因此这儿需要在第一层隐含层之前，引入一个嵌入层来将输入向量压缩到低维稠密向量。</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DeepFM%E4%B8%ADDeep%E9%83%A8%E5%88%86.png" class title="This is an image"><p><strong>嵌入层的网络结构</strong>如下：</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DeepFM%E5%B5%8C%E5%85%A5%E9%83%A8%E5%88%86%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" class title="This is an image"><p>这个网络结构有两个关键点：</p><ul><li>虽然输入的每个field向量长度不一样，但是它们embedding出来的长度是固定的，上图示例的嵌入长度是k=5；</li><li>FM中的隐向量$V$作为该嵌入层的权重矩阵，以实现输入的field向量压缩到embedding向量的转换。隐向量$v_{ik}$是嵌入层中第i个field连接到嵌入层第k个节点的权重。</li></ul><p>这里的第二点可以这样理解：假设我们的k=5，首先，对于输入的一条记录，同一个field 只有一个位置是1，那么在由输入得到dense向量的过程中，输入层只有一个神经元起作用，得到的dense向量其实就是输入层embedding层该神经元相连的五条线的权重，即$v<em>{i1}，v</em>{i2}，v<em>{i3}，v</em>{i4}，v_{i5}$ 。这五个值组合起来就是我们在FM中所提到的$\mathbf{v}_i$,在FM部分和DNN部分，这一块是共享权重的，对同一个特征来说，得到的$\mathbf{v}_i$是相同的。</p><h2 id="与其他神经网络的关系"><a href="#与其他神经网络的关系" class="headerlink" title="与其他神经网络的关系"></a>与其他神经网络的关系</h2><p>下面是FNN、PNN和Wide&amp;Deep模型框架：</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/FNN%E3%80%81PNN%E5%92%8CWide&Deep%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png" class title="This is an image"><p><strong>FNN</strong>是一个FM初始化的前馈神经网络，与DeepFM不同，它是用FM预训练出来的$V$来对Deep部分进行初始化，仅提取到了高阶特征，它有两个限制。</p><ul><li>嵌入层参数可能受FM影响过大。</li><li>预训练阶段引入的开销降低了效率。</li></ul><p><strong>PNN</strong>为了捕获高阶交叉特征，PNN在嵌入层和第一层隐藏层之间增加了一个product层，根据 product 的不同，衍生出三种 PNN：IPNN，OPNN，PNN* 分别对应内积、外积、两者混合。和FNN一样，它只能学习到高阶的特征组合，没有对于1阶和2阶特征进行建模。</p><p><strong>Wide&amp;Deep</strong>将Wide组件和Deep组件进行融合，同时学习低阶和高阶特征，但是wide部分需要人工构造交叉特征。</p><p>下面是它们关于是否需要预训练、是否提取了高阶、低阶特征以及是否需要特征工程的比较：</p><h2 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h2><p>在这篇论文的实验部分中，介绍了所使用的数据集Criteo Dataset和Company∗ Dataset、评估指标AUC和Logloss、性能评估(CPU训练时间和GPU训练时间)、以及超参数学习（包括激活函数、弃权（Dropout）概率、每层神经元数目、隐藏层数目和网络形状）。</p><h1 id="《BPR-Bayesian-Personalized-Ranking-from-Implicit-Feedback》"><a href="#《BPR-Bayesian-Personalized-Ranking-from-Implicit-Feedback》" class="headerlink" title="《BPR: Bayesian Personalized Ranking from Implicit Feedback》"></a>《BPR: Bayesian Personalized Ranking from Implicit Feedback》</h1><h2 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h2><p>目前排序算法大致被分为三类，分别是点对排序(Pointwise)、成对排序(Pairwise)和列表排序(Listwise)。BPR(Bayesian Personalized Ranking，贝叶斯个性化排序)就是属于成对方法（Pairwise）中的一种，成对排序对物品顺序关系是否合理进行判断，判断任意两个物品组成的物品对$<item1,item2>$，是否满足顺序关系，从而最终完成物品的排序任务来得到推荐列表。</item1,item2></p><h2 id="BPR建模思路"><a href="#BPR建模思路" class="headerlink" title="BPR建模思路"></a>BPR建模思路</h2><p>它基于这样的假设，比起其他没有被交互过的物品而言，用户更喜爱对交互过物品(而对于用户交互过的物品对之间不假设偏序关系，同样，对于用户没有交互过的物品对之间也不假设偏序关系)。从而将 “用户-物品 ”交互矩阵可以转换为物品对偏序关系矩阵。如下图所示：</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/BPR%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png" class title="This is an image"><p>上述是交互矩阵转换为物品偏序对矩阵的过程。所有用户的物品偏序对矩阵可以表示成3元组$&lt; u,i,j >$，该三元组的含义为：相对于物品$j$，用更喜欢物品$i$，使用符号$i &gt;<em>u j$表示。令$D_s = {(u,i,j)|i \in I_u^+  \cap j \in I \backslash I_u^+ }$。$I</em>{u}^{+}$表示用户$u$交互过的物品集合，同理，$U_{i}^{+}$表示与物品$i$交互过的用户集合，</p><p>在此基础上 ,作者提出了基于贝叶斯的个性化排序算法，其目标是最大化物品排序的后验概率。它有如下两个假设：一是每个用户对物品的偏好与其他用户无关，即，用户的偏好行为相互独立；二是每个用户在物品$i$和物品$j$之间的偏好和其他商品无关，即，每个用户对不同物品的偏序相互独立。</p><p>在BPR中，排序关系符号$&gt;_u$满足完整性、反对称性和传递性，即对于用户集$U$和物品集$I$：</p><ol><li>完整性：$\forall i,j\in I:i\neq j \Rightarrow i &gt;_u j \cup j&gt;_ui$</li><li>反对称性：$\forall i,j\in I:i&gt;_uj \cap j&gt;_ui\Rightarrow i=j$</li><li>传递性：$\forall i,j,k\in I:i&gt;_uj \cap j&gt;_uk\Rightarrow i&gt;_uk$</li></ol><p>另外，BPR用到了和funkSVD相似的矩阵分解模型，它满足：</p><script type="math/tex; mode=display">\overline{X}=WH^T</script><p>其中左边$\overline{X}$表示BPR对于用户$U$和物品集$I$的对应的$U\times I$的预测排序矩阵，右边$H^T$分别表示希望得到的分解后的用户矩阵$W(|U|\times k)$和物品矩阵$H(|I|\times k)$。BPR是基于用户维度的，故，对于任意一个用户$u$，对应的任一个物品$i$，我们期望有：</p><script type="math/tex; mode=display">\overline{x}_{ui}=w_u \cdot h_i=\sum_{f=1}^{k}w_{uf}h_{if}</script><p>最终目标是希望找到合适的矩阵$W$和$H$，让$\overline{X}$和$X$最相似。下面第3部分BPR的优化思路部分会介绍它和funkSVD有何不同。</p><h2 id="BPR的算法优化思路"><a href="#BPR的算法优化思路" class="headerlink" title="BPR的算法优化思路"></a>BPR的算法优化思路</h2><p>BPR基于最大后验估计$P(W,H|&gt;_u)$来求解模型参数$W,H$，这里我们用$\Theta$来表示模型的参数$W,H$，$&gt;_u$代表用户$u$对应所有商品的全序关系，则优化目标是$P(\Theta|&gt;_u)$。根据贝叶斯公式，我们有：</p><script type="math/tex; mode=display">P(\Theta|>_u)=\frac{P(>_u|\Theta)P(\Theta)}{P(>_u)}</script><p>由于我们求解假设了用户的排序和其他用户无关，那么对任意用户$u$来说，$P(&gt;_u)$对所有的物品一样，所以有：</p><script type="math/tex; mode=display">P(\Theta|>_u)\propto P(>_u|\Theta)P(\Theta)</script><p>可以看出优化目标转化为两部分。$P(&gt;_u|\Theta)$和样本数据集$D_s$有关，$P(\Theta)$和样本数据集$D_s$无关。</p><p>对于第一部分（似然部分），我们假设了用户之间偏好独立，对不同商品偏序独立，故有：</p><script type="math/tex; mode=display">\prod_{u \in U}P(>_u|\Theta) = \prod_{(u,i,j)\in (U\times I \times I)}P(i>_uj|\Theta)^{\delta((u,i,j)\in D_s)}(1-P(i>_uj|\Theta))^{\delta((u,j,i)\notin D_s)}</script><p>其中，</p><script type="math/tex; mode=display">\delta(b)=\begin{cases}1,& if \ b \ is \ true\\0,& else\end{cases}</script><p>根据第2部分介绍到的完整性和反对称性，优化目标的第一部分可以简化为：</p><script type="math/tex; mode=display">\prod_{u \in U}P(>_u|\Theta) = \prod_{(u,i,j)\in D_s}P(i>_uj|\Theta)</script><p>而对于$P(i&gt;_uj|\Theta)$这个概率，我们可以使用下面这个式子来代替：</p><script type="math/tex; mode=display">P(i>_uj|\Theta)=\sigma(\overline{x}_{uij}(\Theta))</script><p>其中$\sigma(x)$是sigmoid函数，对于$\overline{x}<em>{uij}(\Theta)$，我们要满足当$i&gt;_uj$时，$\overline{x}</em>{uij}(\Theta)&gt;0$，反之，当$j &gt;<em>u i$时，$\overline{x}</em>{uij}(\Theta)&lt;0$；那么最简单表示这个性质的方法就是：</p><script type="math/tex; mode=display">\overline{x}_{uij}(\Theta) = \overline{x}_{ui}(\Theta)-\overline{x}_{uj}(\Theta)</script><p>而$\overline{x}<em>{ui},\overline{x}</em>{uj}$就是矩阵$\overline{X}$对应位置的值，为了方便，暂不写$\Theta$；最终，第一部分的优化目标转化为：</p><script type="math/tex; mode=display">\prod_{u \in U}P(>_u|\Theta) = \prod_{(u,i,j)\in D_s}\sigma(\overline{x}_{ui}-\overline{x}_{uj})</script><p>对于第二部$P(\Theta)$，即，先验部分，可以根据参数的假设分布选择，如高斯分布：均值为0，协方差矩阵是$\lambda_\Theta I$，如下：</p><script type="math/tex; mode=display">P(\Theta) \sim N(0,\lambda_\Theta I)</script><p>其中$\lambda_\Theta $是模型的正则化参数。最终，可以得到最大对数后验估计函数：</p><script type="math/tex; mode=display">\begin{aligned}\ln P(\Theta|>_u)&\propto \ln P(>_u|\Theta)P(\Theta)\\&=\ln\prod_{(u,i,j)\in D_s}\sigma(\overline{x}_{ui}-\overline{x}_{uj})+\ln P(\Theta)\\&=\sum_{(u,i,j)\in D}\ln \sigma(\overline{x}_{ui}-\overline{x}_{uj})+\lambda||\Theta||^2\end{aligned}</script><p>由于</p><script type="math/tex; mode=display">\overline{x}_{ui}-\overline{x}_{uj} = \sum_{f=1}^{k}w_{uf}h_{if}-\sum_{f=1}^{k}w_{uf}h_{jf}</script><p>我们求偏导可以得到如下式子：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial (\overline{x}_{ui} - \overline{x}_{uj})}{\partial \Theta} &= \begin{cases} (h_{if}-h_{jf})& {if\; \Theta = w_{uf}}\\ w_{uf}& {if\;\Theta = h_{if}} \\ -w_{uf}& {if\;\Theta = h_{jf}}\end{cases}\end{aligned}</script><h2 id="BPR的算法流程"><a href="#BPR的算法流程" class="headerlink" title="BPR的算法流程"></a>BPR的算法流程</h2><p>下面简要总结下BPR的算法训练流程：</p><p>输入：训练集$D_s$三元组，梯度步长$\alpha$， 正则化参数$\lambda$,分解矩阵维度$k$。　　　　　　　　　　</p><p>输出：模型参数，矩阵W,H。</p><ol><li><p>随机初始化矩阵$W,H$</p></li><li><p>迭代更新参数：</p><script type="math/tex; mode=display">\begin{aligned}w_{uf}=w_{uf}+\alpha(\sum_{(u,i,j)\in D_s}\frac{1}{1+e^{\overline{x}_{ui}-\overline{x}_{uj}}}(h_{if}-h_{jf})+\lambda w_{uf})\\h_{if}=h_{if}+\alpha(\sum_{(u,i,j)\in D_s}\frac{1}{1+e^{\overline{x}_{ui}-\overline{x}_{uj}}}w_{uf}+\lambda h_{if})\\h_{jf}=h_{jf}+\alpha(\sum_{(u,i,j)\in D_s}\frac{1}{1+e^{\overline{x}_{ui}-\overline{x}_{uj}}}w_{uf}+\lambda h_{jf})\end{aligned}</script></li><li><p>如果$W,H$收敛，则算法结束，输出$W,H$；否则回到步骤2。</p></li></ol><p>当我们得到$W,H$后，可以计算出每一个用户$u$对应的任意一个商品的排序分数，最终选择排序分最高的若干商品输出。</p><h2 id="BPR总结"><a href="#BPR总结" class="headerlink" title="BPR总结"></a>BPR总结</h2><p>BPR是基于矩阵分解的一种排序算法，但是和funkSVD之类的算法比，它不是做全局的评分优化，而是针对每一个用户自己的商品喜好分别做排序优化。这篇文章的主要贡献就是提出了上述BPR优化目标。BPR优化目标中的模型$\Theta$可以使用多种多样的模型，包括协同过滤、神经网络等等。</p><h1 id="《From-RankNet-to-LambdaRank-to-LambdaMART-An-Overview》"><a href="#《From-RankNet-to-LambdaRank-to-LambdaMART-An-Overview》" class="headerlink" title="《From RankNet to LambdaRank to LambdaMART: An Overview》"></a>《From RankNet to LambdaRank to LambdaMART: An Overview》</h1><h2 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h2><p>LambdaMART是LambdaRank的提升树版本，而LambdaRank又是基于pairwise的RankNet。因此LambdaMART本质上也是属于pairwise排序算法，只不过引入Lambda梯度后，还显示的考察了列表级的排序指标，如NDCG等，将排序问题转化为回归决策树问题。因此，它算作是listwise中的一种排序算法。</p><p>LambdaMART模型从名字上可以拆分成Lambda和MART两部分：</p><ul><li>MART表示底层训练模型用的是MART（Multiple Additive Regression Tree），也就是GBDT（GradientBoosting Decision Tree）。</li><li>Lambda是<strong>MART求解过程使用的梯度</strong>，其物理含义是一个待排序的物品列表下一次迭代时应该调整的排序方向（向上或者向下）和强度。</li></ul><p>将MART和Lambda组合起来就是我们要介绍的LambdaMART。</p><p>下面逐个介绍RankNet、LambdaRank和LambdaMART三个模型。</p><h2 id="RankNet"><a href="#RankNet" class="headerlink" title="RankNet"></a>RankNet</h2><p>RankNet是一个pairwise模型，它和BPR非常像。创新之处都在于，原本Ranking常见的排序问题评价指标（NDCG、ERR、MAP和MRR）都无法求梯度，因此没法直接对评价指标做梯度下降，而它们将不适宜用梯度下降求解的 Ranking 问题，转化为对偏序概率的交叉熵损失函数的优化问题，从而适用梯度下降方法。</p><p>RankNet的最终目标是得到一个带参的算分函数：</p><script type="math/tex; mode=display">s=f(x;w)</script><p>根据这个算分函数，我们可以计算物品$x_i$和$x_j$的得分$s_i$和$s_j$，即：</p><script type="math/tex; mode=display">s_i = f(x_i;w)   \ \ \ \ s_j=f(x_j;w)</script><p>然后根据得分计算二者的偏序概率：</p><script type="math/tex; mode=display">P_{ij}=P(x_i\rhd x_j)=\frac{1}{1+e^{-\sigma\cdot(s_i-s_j)}}</script><p>其中$\sigma$是Sigmoid函数的参数，决定了Sigmoid曲线的形状。RankNet证明了如果知道一个待排序物品的排列中相邻两个物品之间的排序概率，则通过推导可以算出每两个物品之间的排序概率。因此对于一个待排序物品序列，只需计算相邻物品之间的排序概率，不需要计算所有pair，减少计算量。</p><p>接下来定义标签$S<em>{ij}={1,-1,0}$，$\overline{P}</em>{ij}=\frac{1}{2}(S<em>{ij}+1)$是物品$x_i$比$x_j$排序靠前的真实概率，即当$x_i\rhd x_j$时，$S</em>{ij}=1$，$\overline{P}<em>{ij}=$1；当$x_j\rhd x_i$时，$S</em>{ij}=-1$，$\overline{P}<em>{ij}=0$；否则$S</em>{ij}=0$，$\overline{P}_{ij}=\frac{1}{2}$。</p><p>定义交叉熵作为损失函数衡量$P<em>{ij}$和$\overline{P}</em>{ij}$的拟合程度：</p><script type="math/tex; mode=display">\begin{aligned}C_{ij}&=-\overline{P}_{ij}\log{P_{ij}}-(1-\overline{P}_{ij})\log(1-P_{ij})\\&=-\frac{1}{2}(1+S_{ij})\log{P_{ij}}-(1-\frac{1}{2}(1+S_{ij}))\log(1-P_{ij})\\&=-\frac{1}{2}(1+S_{ij})\log{P_{ij}}-\frac{1}{2}(1-S_{ij})\log(1-P_{ij})\\&=-\frac{1}{2}S_{ij}\log{\frac{1-P_{ij}}{P_{ij}}}-\frac{1}{2}\log(1-P_{ij})\log{P_{ij}}\\&= -\frac{1}{2}S_{ij}(-\sigma\cdot(s_i-s_j))-\frac{\partial{P_{ij}}}{\partial{\sigma\cdot(s_i-s_j)}}\\&= -\frac{1}{2}S_{ij}(-\sigma\cdot(s_i-s_j))-\frac{1}{2}(-\sigma\cdot(s_i-s_j)-2\log(1+e^{-\sigma\cdot(s_i-s_j)}))\\&=\frac{1}{2}(1-S_{ij})\sigma\cdot(s_i-s_j)+\log(1+e^{-\sigma\cdot(s_i-s_j)})\end{aligned}</script><p>上式利用了性质，$P=\frac{1}{1+e^{-x}}\rightarrow x=\log(\frac{P}{1-P}),P(1-P)=\frac{\partial P}{\partial x}$。</p><p>该损失函数有以下两个特点：</p><ul><li>当两个相关性不同的物品算出来的模型分数相同时，因为损失函数后半部分为$\log(1+e^{-\sigma\cdot(s_i-s_j)})$，损失函数的值大于0，仍会对这对pair做惩罚，使他们的排序位置区分开。</li><li>损失函数是一个类线性函数，可以有效减少异常样本数据对模型的影响，因此具有鲁棒性。</li></ul><p>RankNet采用神经网络模型优化损失函数，采用梯度下降法求解：</p><script type="math/tex; mode=display">w_k=w_k-\eta\frac{\partial C}{\partial w_k}</script><h2 id="LambdaRank"><a href="#LambdaRank" class="headerlink" title="LambdaRank"></a>LambdaRank</h2><p>在介绍LambdaRank的动机之前，我们先从一张图来考察RankNet学习过程中，列表的排序变化。</p><img src="/2019/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/05/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/RankNet%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B.png" class title="This is an image"><p>如上所示，每个线条表示物品，蓝色表示相关物品，灰色表示不相关物品，RankNet以pairwise error的方式计算损失，在某次迭代中，RankNet 将物品的顺序从左边变成了右边。于是我们可以看到：</p><ul><li>RankNet 的梯度下降表现在结果的整体变化中是逆序对的下降。左图中，2~14不相关物品都排在了15号相关物品之前，这些不相关物品和15号物品构成的逆序对共13个，因此损失等价于为13；而右图中，将1号相关物品降到了4号，15号相关物品上升到了10号，此时逆序对的数量为3+8=11个，因此损失等价于11.</li><li>对于一些强调最靠前的TopK个物品的排序指标(NDCG、ERR等)而言，上述优化不是理想的。例如，右图下一次迭代，在Ranknet中梯度优化方向如黑色箭头所示，此时损失可以下降到8；然而对于NDCG指标而言，我们更愿意看到红色箭头所示的优化方向（此时Ranknet同样是8，但是NDCG指标相比前一种情况上升了），即关注靠前位置的相关物品排序位置的提升。</li></ul><p>LambdaRank正是基于这个思想演化而来，其中Lambda指的就是红色箭头，代表下一次迭代优化的方向和强度，也就是梯度。故，LambdaRank先对$\frac{\partial C}{\partial w_k}$做因式分解，如下：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial w_k}=\sum_{(i,j)\in P}\frac{\partial C_{ij}}{\partial w_k}=\sum_{(i,j)\in P}(\frac{\partial C_{ij}}{\partial s_i}\frac{\partial s_i}{\partial w_k}+\frac{\partial C_{ij}}{\partial s_j}\frac{\partial s_j}{\partial w_k})</script><p>其中：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial C_{ij}}{\partial s_i}&=\frac{\partial \frac{1}{2}(1-S_{ij})\sigma\cdot(s_i-s_j)+\log(1+e^{-\sigma\cdot(s_i-s_j)})}{\partial s_i}\\&=\sigma\cdot(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma\cdot(s_i-s_j)}})\\&=-\frac{\partial C_{ij}}{\partial s_j}\end{aligned}</script><p>代入上式得：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial w_k}=\sum_{(i,j)\in P}(\sigma\cdot(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma\cdot(s_i-s_j)}}))(\frac{\partial s_i}{\partial w_k}-\frac{\partial s_j}{\partial w_k})</script><p>令：</p><script type="math/tex; mode=display">\lambda_{ij}=\frac{\partial C_{ij}}{\partial s_i}=\sigma\cdot(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma\cdot(s_i-s_j)}})</script><p>考虑对于有序物品对$(i,j)$，有$S_{ij}=1$，于是有简化：</p><script type="math/tex; mode=display">\lambda_{ij}=-\frac{\sigma}{1+e^{\sigma\cdot(s_i-s_j)}}</script><p>因此，考虑偏序对的对称性，对每个物品$x_i$，其Lambda为：</p><script type="math/tex; mode=display">\lambda_i=\sum_{(i,j)\in P}\lambda_{ij}-\sum_{(j,i)\in P}\lambda_{ij}</script><p>每个物品移动的方向和趋势取决于其他所有与之label不同的物品（比它靠前或比它靠后都考虑）。$i$比越多的物品$j$的真实排名越优，则$\lambda_i$越大；反之，越小。</p><p>同时LambdaRank在此基础上，考虑排序评价指标$Z$（比如$NDCG,\Delta|NDCG|$），把交换两个物品的位置引起的评价指标的变化$|\Delta Z_{ij}|$作为其中一个因子，如下：</p><script type="math/tex; mode=display">\lambda_{ij}=-\frac{1}{1+e^{\sigma\cdot(s_i-s_j)}}|\Delta Z_{ij}|</script><p>可以看出，LambdaRank不是直接显示定义损失函数再求梯度的方式对排序问题进行求解，而是分析排序问题需要的梯度的物理意义，直接定义梯度，我们可以反推出LambdaRank的损失函数$L<em>{ij}=\log(1+e^{-\sigma\cdot(s_i-s_j)})|\Delta Z</em>{ij}|$。</p><p>LambdaRank相比RankNet的优势在于分解因式后训练速度变快，同时考虑了评价指标，直接对问题求解，效果更明显。</p><h2 id="LambdaMART"><a href="#LambdaMART" class="headerlink" title="LambdaMART"></a>LambdaMART</h2><p>LambdaRank重新定义了梯度，赋予了梯度新的物理意义，因此，所有可以使用梯度下降法求解的模型都可以使用这个梯度，MART（即GBDT）就是其中一种，MART的原理是直接在函数空间对函数进行求解，模型结果由许多棵树组成，每棵树的拟合目标是损失函数的梯度，在LambdaMART中就是Lambda。就变成这样：</p><ul><li>MART是一个框架，缺少一个<strong>梯度</strong>；</li><li><p>LambdaRank定义了一个<strong>梯度</strong>。</p><p>下面介绍LambdaMART的每一步工作：</p></li></ul><ol><li>每棵数的训练会先遍历所有的训练数据（label不同的物品对pair），计算每个pari互换位置导致的指标变化$|\Delta Z<em>{ij}|$以及Lambda，即$\lambda</em>{ij}=-\frac{1}{1+e^{\sigma\cdot(s<em>i-s_j)}}|\Delta Z</em>{ij}|$，然后计算每个物品档的Lambda：$\lambda<em>i=\sum</em>{(i,j)\in P}\lambda<em>{ij}-\sum</em>{(j,i)\in P}\lambda_{ij}$，再计算每个$\lambda_i$的导数$w_i$，用于后面的牛顿迭代法(Newton step)求解叶子节点的数值。</li><li>创建回归树去拟合第一步生成的$\lambda<em>i$，划分树节点的标准是均方差（MSE），生成一棵叶子节点数为k的回归树$R</em>{km}$，$m$表示第$m$棵树。</li><li>对第二步生成的回归树，计算每个叶子节点的数值，采用牛顿迭代法求解，即对落入该叶子节点的物品集，用公式$\frac{\sum<em>{x_i\in R</em>{km}}\lambda<em>i}{\sum</em>{x<em>i\in R</em>{km}}w_i}$计算该叶子节点的输出值。</li><li>更新模型，将当前学习到的回归树加入到已有的模型中做回归。</li></ol><p>LambdaMART有很多优势：</p><ol><li>适用于排序场景：不是传统的通过分类或者回归的方法求解排序问题，而是直接求解。</li><li>损失函数可导：通过损失函数的转换，将类似于NDCG这种无法求导的排序评价指标转换成可以求导的函数，并且赋予了梯度的实际物理意义。</li><li>增量学习：由于每次训练可以在已有的模型上继续训练，因此适合于增量学习。</li><li>特征选择：因为是基于MART模型，因此也具有MART的优势，可以学到每个特征的重要性，可以做特征选择。</li><li>组合特征：因为采用树模型，因此可以学到不同特征组合情况。</li><li>适用于正负样本比例失衡的数据：因为模型的训练对象具有不同label的物品对pair，而不是预测每个物品的label，因此对正负样本比例失衡不敏感。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
            <tag> 排序学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
